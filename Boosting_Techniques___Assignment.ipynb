{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#  Boosting Techniques | Assignment"
      ],
      "metadata": {
        "id": "h8CBbaoa4Qjw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Question 1: What is Boosting in Machine Learning?\n",
        "\n",
        "## Answer 1:\n",
        "\n",
        "## Definition\n",
        "**Boosting** is an **ensemble learning technique** that combines multiple **weak learners** (usually shallow decision trees) sequentially to form a **strong learner**.\n",
        "\n",
        "Each weak model focuses on correcting the **errors** made by the previous models.  \n",
        "The final prediction is obtained by **weighted voting** (for classification) or **weighted averaging** (for regression).\n",
        "\n",
        "---\n",
        "\n",
        "##  Key Idea\n",
        "\n",
        "Boosting converts weak models (slightly better than random guessing) into a strong, high-accuracy model.\n",
        "\n",
        "- Train the first weak learner on the dataset.  \n",
        "- Evaluate errors and assign **higher weights** to the misclassified samples.  \n",
        "- The next learner focuses more on those **difficult examples**.  \n",
        "- Combine all learners using weighted voting ‚Üí final prediction.\n",
        "\n",
        "---\n",
        "\n",
        "##  Working Mechanism (Simplified Steps)\n",
        "\n",
        "1. **Initialize sample weights** equally for all data points.  \n",
        "2. **Train a weak learner** (e.g., small Decision Tree).  \n",
        "3. **Compute error** of this learner.  \n",
        "4. **Increase weights** of misclassified samples.  \n",
        "5. **Train the next learner** using updated weights.  \n",
        "6. **Combine** all learners (weighted average of predictions).\n",
        "\n",
        "---\n",
        "\n",
        "##  Mathematical Intuition\n",
        "\n",
        "Let there be training samples $(x_1, y_1), (x_2, y_2), ..., (x_n, y_n)$.\n",
        "Each weak learner $h_t(x)$ is assigned a weight $\\alpha_t$ based on its accuracy.\n",
        "\n",
        "The final strong classifier is:\n",
        "\n",
        "$$\n",
        "F(x) = \\text{sign}\\left(\\sum_{t=1}^{T} \\alpha_t \\, h_t(x)\\right)\n",
        "$$\n",
        "\n",
        "where  \n",
        "\n",
        "$$\n",
        "\\alpha_t = \\frac{1}{2} \\ln\\left(\\frac{1 - \\epsilon_t}{\\epsilon_t}\\right)\n",
        "$$\n",
        "\n",
        "and $\\epsilon_t$ is the error rate of the $t^{th}$ weak learner.\n",
        "\n",
        "\n",
        "> üîπ A smaller error ‚Üí larger \\( \\alpha_t \\) ‚Üí higher influence in the final prediction.\n",
        "\n",
        "---\n",
        "\n",
        "## Example: AdaBoost (Adaptive Boosting)\n",
        "\n",
        "- Starts with all samples having equal weights.  \n",
        "- After each tree, increases weights of incorrectly classified samples.  \n",
        "- The final prediction is a **weighted majority vote** of all trees.\n",
        "\n",
        "---\n",
        "\n",
        "##  Why Boosting Improves Weak Learners\n",
        "\n",
        "| Concept | Explanation |\n",
        "|----------|--------------|\n",
        "| **Focus on mistakes** | Each new learner pays more attention to data points the previous ones got wrong. |\n",
        "| **Sequential learning** | Errors get corrected gradually, improving accuracy iteration by iteration. |\n",
        "| **Weighted combination** | Learners that perform better are given higher influence (weights). |\n",
        "| **Bias reduction** | Boosting reduces both bias and variance, improving generalization. |\n",
        "\n",
        "---\n",
        "\n",
        "## üèÅ Advantages of Boosting\n",
        "‚úÖ Converts weak learners into a strong model  \n",
        "‚úÖ Reduces bias and variance  \n",
        "‚úÖ Works well on structured/tabular data  \n",
        "‚úÖ High predictive accuracy\n",
        "\n",
        "---\n",
        "\n",
        "## ‚ö†Ô∏è Limitations\n",
        "‚ùå Sensitive to noisy data and outliers  \n",
        "‚ùå Computationally expensive for large datasets  \n",
        "‚ùå Requires careful tuning of hyperparameters (learning rate, estimators, depth)\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Q_W5tL884V7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train AdaBoost model\n",
        "model = AdaBoostClassifier(n_estimators=50, learning_rate=1.0, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"üéØ Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyvsiLrw5evL",
        "outputId": "79c2c67f-937e-47cb-d812-90ff93dd3e7e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéØ Accuracy: 0.9333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Question 2: What is the Difference Between AdaBoost and Gradient Boosting in Terms of How Models Are Trained?\n",
        "\n",
        "## Answer 2:\n",
        "##  Definition\n",
        "Both **AdaBoost (Adaptive Boosting)** and **Gradient Boosting** are **ensemble techniques** based on **Boosting** ‚Äî a method that combines multiple **weak learners** (usually shallow decision trees) to form a **strong learner**.\n",
        "\n",
        "However, they differ in **how they adjust and train models sequentially**.\n",
        "\n",
        "---\n",
        "\n",
        "##  Key Difference Overview\n",
        "\n",
        "| Feature | **AdaBoost** | **Gradient Boosting** |\n",
        "|----------|---------------|------------------------|\n",
        "| **Main Idea** | Adjusts **sample weights** to focus on misclassified examples. | Fits new models to **residual errors** (gradients of loss). |\n",
        "| **Error Handling** | Misclassified samples get higher weights. | Learner minimizes overall loss via gradient descent. |\n",
        "| **Model Update** | Weighted combination of weak learners. | Additive model using gradient of loss function. |\n",
        "| **Loss Function** | Exponential loss (default). | Any differentiable loss (e.g., squared error, log loss). |\n",
        "| **Training Approach** | Reweights data samples. | Fits to negative gradient of loss function. |\n",
        "| **Interpretation** | Focus on hard samples. | Focus on reducing residual errors. |\n",
        "\n",
        "---\n",
        "\n",
        "##  Intuitive Understanding\n",
        "\n",
        "### üîπ AdaBoost:\n",
        "- Each new weak learner tries to **fix mistakes** of the previous one by **increasing weights** of wrongly predicted samples.  \n",
        "- Works well for classification problems.  \n",
        "- Uses **exponential loss function**.\n",
        "\n",
        "Mathematically:\n",
        "$$\n",
        "\\alpha_t = \\frac{1}{2} \\ln\\left(\\frac{1 - \\epsilon_t}{\\epsilon_t}\\right)\n",
        "$$\n",
        "and final model:\n",
        "$$\n",
        "F(x) = \\text{sign}\\left(\\sum_{t=1}^{T} \\alpha_t h_t(x)\\right)\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "###  Gradient Boosting:\n",
        "- Builds models **stage by stage** by fitting each new learner to the **residuals** (errors) of the previous stage.  \n",
        "- Uses **gradient descent** to minimize a chosen loss function.  \n",
        "- Can be used for both regression and classification.\n",
        "\n",
        "Mathematically:\n",
        "$$\n",
        "F_{m}(x) = F_{m-1}(x) + \\eta \\cdot h_m(x)\n",
        "$$\n",
        "\n",
        "where  \n",
        "- \\( F_{m-1}(x) \\): model after previous iteration  \n",
        "- \\( h_m(x) \\): new weak learner trained on residuals  \n",
        "- \\( \\eta \\): learning rate (step size)\n",
        "\n",
        "---\n",
        "\n",
        "##  Example Analogy\n",
        "\n",
        "| Analogy | AdaBoost | Gradient Boosting |\n",
        "|----------|-----------|------------------|\n",
        "| **Teacher correcting students** | Gives **more focus** (weight) to weak students who failed earlier. | Analyzes **mistakes (residuals)** made by all students and gives lessons targeting those topics. |\n",
        "\n",
        "---\n",
        "\n",
        "##  Summary of Training Approach\n",
        "\n",
        "| Step | AdaBoost | Gradient Boosting |\n",
        "|------|-----------|------------------|\n",
        "| 1Ô∏è‚É£ | Initialize all sample weights equally | Initialize model with a constant value |\n",
        "| 2Ô∏è‚É£ | Train weak learner and calculate weighted error | Compute loss and residuals |\n",
        "| 3Ô∏è‚É£ | Increase weights of misclassified samples | Train weak learner on residuals |\n",
        "| 4Ô∏è‚É£ | Combine learners using weighted sum | Update model using gradient and learning rate |\n",
        "| 5Ô∏è‚É£ | Final strong classifier = weighted sum of all weak learners | Final model = sum of all weak learners fitted to gradients |\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7r0f4nvr6pef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# AdaBoost\n",
        "ada = AdaBoostClassifier(n_estimators=50, learning_rate=0.5, random_state=42)\n",
        "ada.fit(X_train, y_train)\n",
        "ada_pred = ada.predict(X_test)\n",
        "\n",
        "# Gradient Boosting\n",
        "gb = GradientBoostingClassifier(n_estimators=50, learning_rate=0.1, random_state=42)\n",
        "gb.fit(X_train, y_train)\n",
        "gb_pred = gb.predict(X_test)\n",
        "\n",
        "# Accuracy comparison\n",
        "print(f\"üéØ AdaBoost Accuracy: {accuracy_score(y_test, ada_pred):.3f}\")\n",
        "print(f\"üå± Gradient Boosting Accuracy: {accuracy_score(y_test, gb_pred):.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nK-X6meA7DYT",
        "outputId": "93c96f86-6263-4900-aa0a-dde0f2d3b9b4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéØ AdaBoost Accuracy: 0.967\n",
            "üå± Gradient Boosting Accuracy: 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "##  Interpretation\n",
        "\n",
        "- **AdaBoost**: focuses on hard-to-classify samples by adjusting sample weights.  \n",
        "- **Gradient Boosting**: focuses on reducing residual errors using gradient descent.\n",
        "\n",
        " In practice, **Gradient Boosting** (and its variants like **XGBoost**, **LightGBM**) usually perform better on complex datasets.\n",
        "\n",
        "---\n",
        "\n",
        "##  Final Conclusion\n",
        "\n",
        "| Parameter | AdaBoost | Gradient Boosting |\n",
        "|------------|-----------|------------------|\n",
        "| Training Method | Reweight misclassified samples | Fit new models to residuals |\n",
        "| Optimization | Implicit, weight-based | Explicit, gradient-based |\n",
        "| Loss Function | Exponential | Any differentiable loss |\n",
        "| Performance | Simpler, less flexible | More powerful and general |\n",
        "\n",
        " **Gradient Boosting = Generalized, advanced version of AdaBoost.**\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "1ebEvTIq7IrU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Question 3: How Does Regularization Help in XGBoost?\n",
        "\n",
        "## Answer 3:\n",
        "##  Introduction\n",
        "\n",
        "**XGBoost (Extreme Gradient Boosting)** is an advanced implementation of **Gradient Boosting** that includes several optimizations ‚Äî  \n",
        "one of the most important being **Regularization**.\n",
        "\n",
        "Regularization helps control the **complexity of decision trees** to prevent **overfitting**, making the model more **generalized and stable**.\n",
        "\n",
        "---\n",
        "\n",
        "##  What is Regularization?\n",
        "\n",
        "Regularization adds a **penalty term** to the model‚Äôs objective (loss) function to discourage **overly complex models**.\n",
        "\n",
        "Without regularization, the model might keep learning fine details and **noise** in the training data ‚Äî leading to **poor performance on unseen data**.\n",
        "\n",
        "---\n",
        "\n",
        "##  XGBoost Objective Function\n",
        "\n",
        "In XGBoost, the **objective function** to minimize is:\n",
        "\n",
        "$$\n",
        "\\text{Obj} = \\sum_{i=1}^{n} l(y_i, \\hat{y}_i) + \\sum_{k=1}^{K} \\Omega(f_k)\n",
        "$$\n",
        "\n",
        "where:\n",
        "- $l(y_i, \\hat{y}_i)$ ‚Üí loss function (e.g., mean squared error, log loss)  \n",
        "- $\\Omega(f_k)$ ‚Üí regularization term for tree $f_k$\n",
        "\n",
        "---\n",
        "\n",
        "### üîπ Regularization Term\n",
        "\n",
        "$$\n",
        "\\Omega(f) = \\gamma T + \\frac{1}{2} \\lambda \\sum_{j=1}^{T} w_j^2\n",
        "$$\n",
        "\n",
        "where:\n",
        "- $T$ = number of leaves in the tree  \n",
        "- $w_j$ = score (weight) assigned to leaf $j$  \n",
        "- $\\gamma$ = penalty for each leaf (controls number of leaves)  \n",
        "- $\\lambda$ = L2 regularization term (controls leaf weights)\n",
        "\n",
        "---\n",
        "\n",
        "##  Role of Each Regularization Parameter\n",
        "\n",
        "| Parameter | Type | Role | Effect |\n",
        "|------------|------|------|--------|\n",
        "| **Œª (lambda)** | L2 Regularization | Penalizes large leaf weights | Prevents overfitting by smoothing weights |\n",
        "| **Œ± (alpha)** | L1 Regularization | Encourages sparsity in weights | Makes model simpler and faster |\n",
        "| **Œ≥ (gamma)** | Tree Complexity Penalty | Adds cost for creating new leaf nodes | Controls tree growth and structure |\n",
        "\n",
        "---\n",
        "\n",
        "##  Intuitive Example\n",
        "\n",
        "Think of a **student learning a topic**:\n",
        "\n",
        "- Without regularization ‚Üí the student memorizes every example (overfits).\n",
        "- With regularization ‚Üí the student focuses on the main concepts, ignoring unnecessary details (generalizes better).\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1bXgJygn7kSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "model1 = XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    reg_lambda=0,   # No L2 regularization\n",
        "    reg_alpha=0,    # No L1 regularization\n",
        "    gamma=0,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='mlogloss'\n",
        ")\n",
        "model1.fit(X_train, y_train)\n",
        "pred1 = model1.predict(X_test)\n",
        "\n",
        "\n",
        "model2 = XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    reg_lambda=10,   # L2 regularization\n",
        "    reg_alpha=5,     # L1 regularization\n",
        "    gamma=2,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='mlogloss'\n",
        ")\n",
        "model2.fit(X_train, y_train)\n",
        "pred2 = model2.predict(X_test)\n",
        "\n",
        "print(f\"Without Regularization Accuracy: {accuracy_score(y_test, pred1):.3f}\")\n",
        "print(f\"With Regularization Accuracy: {accuracy_score(y_test, pred2):.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9v0RM3g98I0W",
        "outputId": "4015cbd1-f57c-43d6-fabd-6ec35dac1768"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Without Regularization Accuracy: 1.000\n",
            "With Regularization Accuracy: 1.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [10:09:42] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "##  Interpretation\n",
        "\n",
        "- The **regularized model** might have **slightly lower training accuracy** but **higher test accuracy**.  \n",
        "- This shows it has **better generalization** and **reduced overfitting**.\n",
        "\n",
        "---\n",
        "\n",
        "##  Summary\n",
        "\n",
        "| Concept | Description |\n",
        "|----------|--------------|\n",
        "| **Purpose** | Prevent overfitting by penalizing complex trees |\n",
        "| **Methods Used** | L1 (alpha), L2 (lambda), and tree complexity penalty (gamma) |\n",
        "| **Effect** | Simplifies model, improves generalization, increases stability |\n",
        "| **In Short** | Regularization = Simplicity + Stability + Better Performance |\n",
        "\n",
        "---\n",
        "\n",
        "##  Final Conclusion\n",
        "\n",
        " **Regularization in XGBoost** ensures that the model doesn‚Äôt just memorize training data.  \n",
        "It penalizes unnecessary complexity, resulting in a model that is **robust**, **interpretable**, and **performs well on unseen data**.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "BnImuxS58bYR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Question 4: Why Is CatBoost Considered Efficient for Handling Categorical Data?\n",
        "\n",
        "## Answer 4:\n",
        "\n",
        "##  Introduction\n",
        "\n",
        "**CatBoost (Categorical Boosting)** is a gradient boosting algorithm developed by **Yandex**.  \n",
        "It is specifically optimized to handle **categorical features** efficiently ‚Äî without requiring\n",
        "manual preprocessing like **label encoding** or **one-hot encoding**.\n",
        "\n",
        "---\n",
        "\n",
        "##  Key Challenge With Categorical Data\n",
        "\n",
        "Most machine-learning algorithms cannot directly process **non-numerical (string-type)** features.  \n",
        "Traditional encoders introduce several problems:\n",
        "\n",
        "- ‚ö†Ô∏è **Label Encoding:** Imposes an artificial numeric order (e.g., Red = 1, Blue = 2, Green = 3)  \n",
        "- ‚ö†Ô∏è **One-Hot Encoding:** Increases dimensionality drastically when categories are many  \n",
        "- ‚ö†Ô∏è **High Cardinality:** Leads to sparse matrices and slower training  \n",
        "\n",
        "CatBoost solves all of these efficiently and automatically.\n",
        "\n",
        "---\n",
        "\n",
        "##  How CatBoost Handles Categorical Data\n",
        "\n",
        "CatBoost converts categorical features into numerical values using **target-based statistics**,  \n",
        "while applying techniques to avoid **target leakage** and **overfitting**.\n",
        "\n",
        "###  1. Ordered Target Encoding\n",
        "\n",
        "Instead of using the whole dataset to compute averages, CatBoost computes statistics in an **ordered** way ‚Äî  \n",
        "using only the **previous samples** when encoding the current sample.\n",
        "\n",
        "For a feature value \\( x_{i,k} \\):\n",
        "\n",
        "$$\n",
        "\\text{EncodedValue}(x_{i,k}) = \\frac{\\sum_{j < i} [x_{j,k} = x_{i,k}] \\cdot y_j + a \\cdot P}{\\sum_{j < i} [x_{j,k} = x_{i,k}] + a}\n",
        "$$\n",
        "\n",
        "where:  \n",
        "- \\( y_j \\) = target value of the \\( j^{th} \\) record  \n",
        "- \\( a \\) = smoothing parameter  \n",
        "- \\( P \\) = prior (mean target value)  \n",
        "\n",
        " This prevents **data leakage** because the model never looks at the current sample‚Äôs true label when encoding it.\n",
        "\n",
        "---\n",
        "\n",
        "###  2. Efficient Combination of Categorical Features\n",
        "\n",
        "CatBoost automatically creates and evaluates **combinations** of categorical features  \n",
        "(e.g., *City + Device Type*) to capture more complex patterns without manual feature engineering.\n",
        "\n",
        "---\n",
        "\n",
        "###  3. Symmetric Tree Structure\n",
        "\n",
        "CatBoost builds **balanced (symmetric)** trees ‚Äî  \n",
        "all leaves at the same depth use the **same splitting feature**, making the model:\n",
        "\n",
        "-  Faster to train and predict  \n",
        "-  More memory-efficient  \n",
        "-  Easier to parallelize  \n",
        "\n",
        "---\n",
        "\n",
        "##  Advantages Summary\n",
        "\n",
        "| Feature | CatBoost Advantage |\n",
        "|----------|--------------------|\n",
        "| Categorical Encoding | Handles categories natively using ordered statistics |\n",
        "| High Cardinality | Avoids one-hot explosion |\n",
        "| Overfitting Control | Uses ordered boosting and target regularization |\n",
        "| Speed | Builds symmetric trees for fast computation |\n",
        "| Simplicity | No need for manual preprocessing or tuning encoders |\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "-wLPV5Cs844p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# Sample data\n",
        "data = pd.DataFrame({\n",
        "    'Gender': ['Male', 'Female', 'Female', 'Male', 'Female', 'Male'],\n",
        "    'City': ['Delhi', 'Mumbai', 'Delhi', 'Chennai', 'Chennai', 'Mumbai'],\n",
        "    'Income': [45000, 54000, 58000, 39000, 62000, 47000],\n",
        "    'Purchased': [0, 1, 1, 0, 1, 0]\n",
        "})\n",
        "\n",
        "# Split\n",
        "X = data[['Gender', 'City', 'Income']]\n",
        "y = data['Purchased']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train CatBoost model\n",
        "model = CatBoostClassifier(verbose=0, iterations=100, learning_rate=0.1, depth=4)\n",
        "model.fit(X_train, y_train, cat_features=[0, 1])\n",
        "\n",
        "pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8jfTFnq9Lx8",
        "outputId": "1d4e2102-8e10-4386-f974-e4714637b728"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 5: Real-World Applications Where Boosting Techniques Are Preferred Over Bagging Methods\n",
        "\n",
        "## Answer 5:\n",
        "##  Introduction\n",
        "\n",
        "Both **Bagging** (e.g., Random Forest) and **Boosting** (e.g., AdaBoost, Gradient Boosting, XGBoost, CatBoost)  \n",
        "are **ensemble learning** methods that combine multiple weak models to form a strong predictor.\n",
        "\n",
        "However, **Boosting techniques** are generally preferred when:\n",
        "- High accuracy and interpretability are needed  \n",
        "- Data contains **complex patterns** or **non-linear relationships**  \n",
        "- Slightly higher computation time is acceptable for better predictive performance\n",
        "\n",
        "---\n",
        "\n",
        "##  Key Difference in Philosophy\n",
        "\n",
        "| Feature | Bagging (e.g., Random Forest) | Boosting (e.g., XGBoost, AdaBoost) |\n",
        "|----------|-------------------------------|------------------------------------|\n",
        "| **Approach** | Trains models in parallel | Trains models sequentially |\n",
        "| **Focus** | Reduces variance | Reduces bias |\n",
        "| **Best For** | Noisy datasets | Complex structured datasets |\n",
        "| **Output** | Simple averaging/voting | Weighted sum of weak learners |\n",
        "| **Example Use** | Quick baseline models | High-accuracy predictive systems |\n",
        "\n",
        "---\n",
        "\n",
        "##  Real-World Applications of Boosting\n",
        "\n",
        "Below are **practical domains** where boosting consistently outperforms bagging-based methods:\n",
        "\n",
        "---\n",
        "\n",
        "###  1. **Credit Scoring and Loan Default Prediction (Finance)**\n",
        "\n",
        "Boosting algorithms (like XGBoost or LightGBM) are widely used by banks and fintech companies to:\n",
        "\n",
        "- Predict **loan default risk**  \n",
        "- Assess **creditworthiness**  \n",
        "- Detect **fraudulent transactions**  \n",
        "\n",
        "Because boosting models can handle **imbalanced data** and capture **non-linear relationships** between features.\n",
        "\n",
        " Example:  \n",
        "A bank uses **XGBoost** to rank customers by default risk based on income, spending history, and payment patterns.\n",
        "\n",
        "---\n",
        "\n",
        "###  2. **Customer Churn Prediction (Telecom and SaaS)**\n",
        "\n",
        "Boosting is used to predict which customers are likely to **stop using a service**,  \n",
        "helping companies plan retention strategies.\n",
        "\n",
        "- Handles complex patterns in behavioral and transactional data  \n",
        "- Performs better than Random Forest when features interact in non-linear ways\n",
        "\n",
        " Example:  \n",
        "A telecom company uses **CatBoost** to predict churn using categorical data such as region, plan type, and usage frequency.\n",
        "\n",
        "---\n",
        "\n",
        "###  3. **Fraud Detection (Banking and E-commerce)**\n",
        "\n",
        "Boosting excels in **imbalanced classification problems**, where fraudulent transactions are rare.\n",
        "\n",
        "- Learns subtle differences between fraud and legitimate transactions  \n",
        "- Sequential learning helps refine errors of previous models\n",
        "\n",
        " Example:  \n",
        "An e-commerce platform uses **LightGBM** to flag suspicious transactions in real time.\n",
        "\n",
        "---\n",
        "\n",
        "###  4. **Search Engine Ranking (Information Retrieval)**\n",
        "\n",
        "Boosting algorithms (like **LambdaMART**, a type of Gradient Boosting) are used by companies like **Google**, **Bing**, and **Yandex** for:\n",
        "\n",
        "- Ranking web pages based on relevance  \n",
        "- Optimizing search engine result order  \n",
        "\n",
        "Because boosting can optimize **pairwise ranking losses**, improving click-through rates.\n",
        "\n",
        "---\n",
        "\n",
        "###  5. **Medical Diagnosis and Bioinformatics**\n",
        "\n",
        "Boosting methods are popular in healthcare for disease prediction because they can combine many weak predictors  \n",
        "(e.g., symptoms, genetic markers, medical history) into an accurate diagnostic model.\n",
        "\n",
        "üìä Example:  \n",
        "Predicting **breast cancer risk** using **Gradient Boosting Classifier** on diagnostic features.\n",
        "\n",
        "---\n",
        "\n",
        "###  6. **Online Advertising and Click-Through Rate (CTR) Prediction**\n",
        "\n",
        "Boosting is preferred by companies like **Facebook**, **LinkedIn**, and **Google Ads** to predict ad click probabilities.\n",
        "\n",
        "- Handles huge feature spaces  \n",
        "- Can model user behavior and contextual interactions accurately\n",
        "\n",
        " Example:  \n",
        "Using **XGBoost** to predict which ad a user is most likely to click.\n",
        "\n",
        "---\n",
        "\n",
        "##  Summary Table\n",
        "\n",
        "| Domain | Example Use | Preferred Boosting Algorithm |\n",
        "|---------|--------------|------------------------------|\n",
        "| Finance | Credit scoring, fraud detection | XGBoost, LightGBM |\n",
        "| Telecom | Churn prediction | CatBoost |\n",
        "| Healthcare | Disease prediction | Gradient Boosting |\n",
        "| E-commerce | Purchase/fraud prediction | XGBoost |\n",
        "| Search Engines | Ranking | LambdaMART |\n",
        "| Marketing | CTR prediction | LightGBM |\n",
        "\n",
        "---\n",
        "\n",
        "##  Why Boosting Works Better Here\n",
        "\n",
        "- Sequential learning corrects errors from previous models  \n",
        "- Better at reducing **bias** in complex, high-dimensional data  \n",
        "- Robust to **imbalanced** and **heterogeneous** data  \n",
        "- Produces **state-of-the-art accuracy** in many Kaggle competitions and real-world tasks\n",
        "\n",
        "---\n",
        "\n",
        "##  Final Conclusion\n",
        "\n",
        " **Boosting techniques** like XGBoost, LightGBM, and CatBoost are preferred over bagging methods  \n",
        "in applications that demand **high predictive accuracy**, **complex pattern detection**, and **efficient handling of categorical and imbalanced data**.  \n",
        "\n",
        "They power most modern AI systems used in **finance, healthcare, marketing, and search engines** today.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "Pqy89R5B9imz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Question 6\n",
        "### Train an AdaBoost Classifier on the Breast Cancer dataset and print the model accuracy.\n",
        "\n",
        "## Answer 6:\n",
        "\n",
        "##  Theory: AdaBoost (Adaptive Boosting)\n",
        "\n",
        "**Boosting** is an *ensemble learning* technique that combines multiple **weak learners** (usually shallow decision trees) to create a **strong classifier**.\n",
        "\n",
        "In **AdaBoost (Adaptive Boosting)**, models are trained **sequentially**, and each new model focuses on **correcting the mistakes** made by the previous ones.  \n",
        "It assigns **higher weights** to misclassified samples so that subsequent models pay more attention to them.\n",
        "\n",
        "---\n",
        "\n",
        "###  Working Steps\n",
        "\n",
        "1. Start with **equal weights** for all samples.  \n",
        "2. Train a **weak learner** (e.g., decision stump).  \n",
        "3. Compute its **error rate** $ \\epsilon_t $.  \n",
        "4. Assign a **weight** to the model based on its accuracy:\n",
        "\n",
        "   $$\n",
        "   \\alpha_t = \\frac{1}{2} \\ln\\left(\\frac{1 - \\epsilon_t}{\\epsilon_t}\\right)\n",
        "   $$\n",
        "\n",
        "5. **Increase weights** of misclassified samples and **decrease weights** of correctly classified ones.  \n",
        "6. Combine all weak learners to form the final strong classifier:\n",
        "\n",
        "   $$\n",
        "   F(x) = \\text{sign}\\left(\\sum_{t=1}^{T} \\alpha_t \\, h_t(x)\\right)\n",
        "   $$\n",
        "\n",
        "---\n",
        "\n",
        "###  Key Points\n",
        "\n",
        "- AdaBoost **reduces bias** and improves model accuracy.  \n",
        "- Performs well on **clean, moderate-sized datasets**.  \n",
        "- Can **overfit** if data is noisy or too many estimators are used.  \n",
        "- Works best for **binary classification problems**.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "U1YpA9CS-vwN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "model = AdaBoostClassifier(n_estimators=100, learning_rate=1.0, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"üéØ AdaBoost Classifier Accuracy on Breast Cancer Dataset: {:.2f}%\".format(accuracy * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I65UIOvO_KoN",
        "outputId": "7a0deeee-0a13-493d-d993-b108dfb8e752"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéØ AdaBoost Classifier Accuracy on Breast Cancer Dataset: 97.37%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "###  Summary Table\n",
        "\n",
        "| Feature | Description |\n",
        "|----------|--------------|\n",
        "| **Algorithm** | AdaBoost (Adaptive Boosting) |\n",
        "| **Base Learner** | Decision Stump (1-level Decision Tree) |\n",
        "| **Dataset** | Breast Cancer (Classification) |\n",
        "| **Metric** | Accuracy |\n",
        "| **Expected Accuracy** | ~95‚Äì97% |\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "jTLXtO6y_cl2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Question 7\n",
        "### Train a Gradient Boosting Regressor on the California Housing dataset and evaluate its performance using R-squared score.\n",
        "\n",
        "## Answer 7:\n",
        "\n",
        "##  Theory: Gradient Boosting Regressor (GBR)\n",
        "\n",
        "**Gradient Boosting** is an *ensemble learning technique* that builds models **sequentially** to minimize the prediction error.  \n",
        "Each new model tries to **correct the errors (residuals)** made by the previous models.\n",
        "\n",
        "It uses the concept of **gradient descent** ‚Äî each tree is trained to predict the **negative gradient of the loss function** with respect to the model's predictions.\n",
        "\n",
        "---\n",
        "\n",
        "###  Key Formula\n",
        "\n",
        "At iteration **t**, the new model updates predictions as:\n",
        "\n",
        "$$\n",
        "F_t(x) = F_{t-1}(x) + \\eta \\, h_t(x)\n",
        "$$\n",
        "\n",
        "where:  \n",
        "- $ F_t(x) $ ‚Üí updated model after $t$ iterations  \n",
        "- $ F_{t-1}(x) $ ‚Üí previous model  \n",
        "- $ \\eta $ ‚Üí learning rate (controls contribution of each tree)  \n",
        "- $ h_t(x) $ ‚Üí new weak learner (Decision Tree) trained on residuals  \n",
        "\n",
        "---\n",
        "\n",
        "###  R-squared (Coefficient of Determination)\n",
        "\n",
        "The R¬≤ score measures how well the model explains the variance in the target variable.\n",
        "\n",
        "$$\n",
        "R^2 = 1 - \\frac{\\sum (y_i - \\hat{y}_i)^2}{\\sum (y_i - \\bar{y})^2}\n",
        "$$\n",
        "\n",
        "where:  \n",
        "- $ y_i $ ‚Üí actual values  \n",
        "- $ \\hat{y}_i $ ‚Üí predicted values  \n",
        "- $ \\bar{y} $ ‚Üí mean of actual values  \n",
        "\n",
        "---\n",
        "\n",
        "###  Key Points\n",
        "- Gradient Boosting reduces both **bias** and **variance**.  \n",
        "- It works well for **regression and classification** problems.  \n",
        "- Hyperparameters like `n_estimators`, `max_depth`, and `learning_rate` control model performance.  \n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "VrrjGtB6_fsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "\n",
        "data = fetch_california_housing()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "model = GradientBoostingRegressor(\n",
        "    n_estimators=200, learning_rate=0.1, max_depth=3, random_state=42\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"üìà Gradient Boosting Regressor R¬≤ Score on California Housing Dataset: {:.4f}\".format(r2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XfvE00OAThu",
        "outputId": "52a9e08a-e47f-43d1-95e1-60f45bf12377"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìà Gradient Boosting Regressor R¬≤ Score on California Housing Dataset: 0.8004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "###  Summary Table\n",
        "\n",
        "| Feature | Description |\n",
        "|----------|--------------|\n",
        "| **Algorithm** | Gradient Boosting Regressor |\n",
        "| **Base Learner** | Decision Tree |\n",
        "| **Dataset** | California Housing (Regression) |\n",
        "| **Metric** | R¬≤ Score |\n",
        "| **Expected Accuracy** | ~0.80 ‚Äì 0.85 |\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "6P51gNzFAd2E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Question 8\n",
        "### Train an XGBoost Classifier on the Breast Cancer dataset, tune the learning rate using GridSearchCV, and print the best parameters and accuracy.\n",
        "\n",
        "## Answer 8:\n",
        "\n",
        "##  Theory: XGBoost (Extreme Gradient Boosting)\n",
        "\n",
        "**XGBoost** is an advanced and optimized version of Gradient Boosting.  \n",
        "It is designed for **speed, regularization, and scalability**.\n",
        "\n",
        "Each tree is built **sequentially**, where the next tree corrects the errors of the previous ones.  \n",
        "It adds **regularization terms** to control overfitting and uses **second-order gradients** for faster convergence.\n",
        "\n",
        "---\n",
        "\n",
        "###  Objective Function\n",
        "\n",
        "$$\n",
        "\\text{Obj} = \\sum_{i=1}^{n} l(y_i, \\hat{y}_i) + \\sum_{k=1}^{K} \\Omega(f_k)\n",
        "$$\n",
        "\n",
        "where  \n",
        "\n",
        "- \\( l(y_i, \\hat{y}_i) \\) ‚Üí loss function (e.g., log-loss)  \n",
        "- \\( \\Omega(f_k) \\) ‚Üí regularization term for tree \\( f_k \\)\n",
        "\n",
        "---\n",
        "\n",
        "###  Regularization Term\n",
        "\n",
        "$$\n",
        "\\Omega(f) = \\gamma T + \\frac{1}{2} \\lambda \\sum_{j=1}^{T} w_j^2\n",
        "$$\n",
        "\n",
        "where  \n",
        "\n",
        "- \\( T \\) ‚Üí number of leaves  \n",
        "- \\( w_j \\) ‚Üí weight of leaf *j*  \n",
        "- \\( \\gamma \\) ‚Üí penalty for each leaf (controls tree complexity)  \n",
        "- \\( \\lambda \\) ‚Üí L2 regularization term (controls leaf weights)\n",
        "\n",
        "---\n",
        "\n",
        "###  Learning Rate (Œ∑)\n",
        "\n",
        "The **learning rate** controls how much each new tree contributes to the model.  \n",
        "\n",
        "$$\n",
        "F_t(x) = F_{t-1}(x) + \\eta \\, h_t(x)\n",
        "$$\n",
        "\n",
        "- Smaller Œ∑ ‚Üí slower but more accurate learning  \n",
        "- Larger Œ∑ ‚Üí faster but risk of overfitting  \n",
        "\n",
        "---\n",
        "\n",
        "###  Key Points\n",
        "- Uses **shrinkage** (learning rate) and **regularization** to reduce overfitting  \n",
        "- Handles **missing values** automatically  \n",
        "- Provides **feature importance** and parallelized tree building  \n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "XM-WWZYUArZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "xgb = XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=3,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "param_grid = {\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=xgb,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"‚úÖ Best Parameters:\", grid_search.best_params_)\n",
        "print(\"üéØ XGBoost Classifier Accuracy: {:.2f}%\".format(accuracy * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3F8iFa_YA_Dj",
        "outputId": "1a5318c7-0f04-4c05-871b-01cd49200c50"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [10:31:09] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Best Parameters: {'learning_rate': 0.3}\n",
            "üéØ XGBoost Classifier Accuracy: 95.61%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "###  Summary Table\n",
        "\n",
        "| Feature | Description |\n",
        "|----------|--------------|\n",
        "| **Algorithm** | XGBoost Classifier |\n",
        "| **Hyperparameter Tuned** | Learning Rate (Œ∑) |\n",
        "| **Dataset** | Breast Cancer (Classification) |\n",
        "| **Evaluation Metric** | Accuracy |\n",
        "| **Expected Accuracy** | ~96‚Äì98% |\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "pMJYc4eABUsM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Question 9\n",
        "### Train a CatBoost Classifier and plot the confusion matrix using Seaborn\n",
        "\n",
        "## Answer 9:\n",
        "\n",
        "##  Theory ‚Äì CatBoost (Classification)\n",
        "\n",
        "**CatBoost** (Categorical Boosting) is a gradient-boosting algorithm developed by Yandex.  \n",
        "It is specially optimized to handle **categorical features efficiently** and reduce **overfitting**.\n",
        "\n",
        "CatBoost is based on **Gradient Boosting on Decision Trees (GBDT)** but uses two major improvements:\n",
        "\n",
        "1. **Ordered Boosting** ‚Äì prevents target leakage by using permutations during training.  \n",
        "2. **Efficient categorical encoding** ‚Äì automatically converts categorical values into numerical statistics.\n",
        "\n",
        "---\n",
        "\n",
        "###  Mathematical Objective\n",
        "\n",
        "The model minimizes the following objective function:\n",
        "\n",
        "$$\n",
        "\\text{Obj} = \\sum_{i=1}^{n} l(y_i, \\hat{y}_i) + \\sum_{k=1}^{K} \\Omega(f_k)\n",
        "$$\n",
        "\n",
        "where  \n",
        "\n",
        "- - $l(y_i, \\hat{y}_i)$ ‚Üí loss function (e.g., log-loss)  \n",
        "- $\\Omega(f_k)$ ‚Üí regularization term for each tree\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "###  Advantages of CatBoost\n",
        "- Handles **categorical data** automatically (no manual encoding needed).  \n",
        "- **Fast training** and **less tuning** required.  \n",
        "- Prevents **overfitting** using *ordered boosting*.  \n",
        "- Supports **GPU training** for large datasets.  \n",
        "\n",
        "---\n",
        "\n",
        "###  Confusion Matrix\n",
        "\n",
        "A **confusion matrix** shows how well a classification model performs by comparing **actual vs predicted** classes.\n",
        "\n",
        "|                | Predicted Positive | Predicted Negative |\n",
        "|----------------|--------------------|--------------------|\n",
        "| **Actual Positive** | True Positive (TP) | False Negative (FN) |\n",
        "| **Actual Negative** | False Positive (FP) | True Negative (TN) |\n",
        "\n",
        "The matrix helps calculate metrics like **Accuracy**, **Precision**, **Recall**, and **F1-Score**.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "kyeDn29BBXdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "model = CatBoostClassifier(\n",
        "    iterations=200,\n",
        "    learning_rate=0.1,\n",
        "    depth=6,\n",
        "    verbose=0,\n",
        "    random_state=42\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(\"üéØ CatBoost Classifier Accuracy: {:.2f}%\".format(acc * 100))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=data.target_names,\n",
        "            yticklabels=data.target_names)\n",
        "plt.title('üß© Confusion Matrix ‚Äì CatBoost Classifier')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "5CaEoD62CI5z",
        "outputId": "f3c2b256-f91e-4688-95f1-fcd5142f2698"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéØ CatBoost Classifier Accuracy: 96.49%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 129513 (\\N{JIGSAW PUZZLE PIECE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Question 10\n",
        "### Predicting Loan Default Using Boosting Techniques in FinTech\n",
        "\n",
        "## Answer 10:\n",
        "\n",
        "##  Theory\n",
        "\n",
        "**Problem:**  \n",
        "We aim to predict whether a customer will default on a loan based on demographics and transaction history.  \n",
        "Challenges: **imbalanced dataset**, **missing values**, **categorical & numeric features**.\n",
        "\n",
        "Boosting algorithms (AdaBoost, XGBoost, CatBoost) combine multiple weak learners to form a **strong predictive model**. They are ideal for tabular data with mixed feature types.\n",
        "\n",
        "---\n",
        "\n",
        "### üîπ Step 1: Data Preprocessing\n",
        "\n",
        "- **Missing Values**:\n",
        "  - Numeric ‚Üí impute median  \n",
        "  - Categorical ‚Üí impute 'Unknown' or let CatBoost handle it  \n",
        "  - Create binary indicator if missingness is informative\n",
        "- **Categorical Encoding**:\n",
        "  - CatBoost: handles categorical natively  \n",
        "  - XGBoost/LightGBM: use one-hot or target encoding\n",
        "- **Class Imbalance**:\n",
        "  - Use `class_weight` or `scale_pos_weight`  \n",
        "  - Oversample minority class (SMOTE) if needed\n",
        "- **Feature Engineering**:\n",
        "  - Aggregated transactional features (avg balance, volatility, number of late payments)  \n",
        "  - Ratios (debt/income), recency, interaction features\n",
        "\n",
        "---\n",
        "\n",
        "### üîπ Step 2: Choice of Boosting Algorithm\n",
        "\n",
        "| Algorithm  | Strength | Recommendation |\n",
        "|------------|---------|----------------|\n",
        "| AdaBoost   | Simple, emphasizes misclassified points | Not preferred for complex tabular data |\n",
        "| XGBoost    | High performance, numeric features | Good baseline |\n",
        "| CatBoost   | Handles categorical & missing values natively | **Recommended** for this use case |\n",
        "\n",
        "---\n",
        "\n",
        "### üîπ Step 3: Hyperparameter Tuning\n",
        "\n",
        "- **Parameters**: `learning_rate`, `depth`, `iterations`, `l2_leaf_reg`, `subsample`  \n",
        "- Use **RandomizedSearchCV** or **GridSearchCV** with **StratifiedKFold**  \n",
        "- Use **early stopping** on validation set to prevent overfitting\n",
        "\n",
        "---\n",
        "\n",
        "### üîπ Step 4: Evaluation Metrics\n",
        "\n",
        "- **Average Precision (AP)** / **Precision-Recall AUC** ‚Üí best for imbalanced classes  \n",
        "- **ROC AUC** ‚Üí ranking performance  \n",
        "- **F1-score** ‚Üí balance precision & recall  \n",
        "- **Confusion Matrix** ‚Üí visualize TP, TN, FP, FN  \n",
        "- **Business metrics** ‚Üí expected monetary loss\n",
        "\n",
        "---\n",
        "\n",
        "### üîπ Step 5: Business Benefits\n",
        "\n",
        "- Reduce loan losses by identifying high-risk customers  \n",
        "- Allocate manual review to top predicted risky applications  \n",
        "- Improve risk-based pricing with calibrated probabilities  \n",
        "- Explainable predictions for compliance (e.g., SHAP values)\n",
        "\n",
        "---\n",
        "\n",
        "### üîπ Boosting Objective Function\n",
        "\n",
        "$$\n",
        "\\text{Obj} = \\sum_{i=1}^{n} l(y_i, \\hat{y}_i) + \\sum_{k=1}^{K} \\Omega(f_k)\n",
        "$$\n",
        "\n",
        "\n",
        "Where:  \n",
        "- $l(y_i, \\hat{y}_i)$ ‚Üí loss function (log-loss)  \n",
        "- $\\Omega(f_k)$ ‚Üí regularization term per tree  \n",
        "\n",
        "Regularization:  \n",
        "$$\n",
        "\\Omega(f) = \\gamma T + \\frac{1}{2} \\lambda \\sum_{j=1}^{T} w_j^2\n",
        "$$\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "DAvKkR11DZOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install catboost seaborn -q\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from catboost import CatBoostClassifier\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target\n",
        "\n",
        "# Add a categorical column for demonstration\n",
        "X['gender'] = ['Male' if i%2==0 else 'Female' for i in range(len(X))]\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "cat_features = [X_train.columns.get_loc('gender')]  # index of categorical column\n",
        "\n",
        "model = CatBoostClassifier(\n",
        "    iterations=300,\n",
        "    learning_rate=0.05,\n",
        "    depth=6,\n",
        "    loss_function='Logloss',\n",
        "    eval_metric='AUC',\n",
        "    cat_features=cat_features,\n",
        "    verbose=100,\n",
        "    random_seed=42\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train, eval_set=(X_test, y_test), use_best_model=True)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=data.target_names,\n",
        "            yticklabels=data.target_names)\n",
        "plt.title(\"Confusion Matrix ‚Äì CatBoost Classifier\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "id": "l0DZG1ooEG9t",
        "outputId": "64e13a04-1b50-4c49-f727-df54d875bdf9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\ttest: 0.9560185\tbest: 0.9560185 (0)\ttotal: 5.91ms\tremaining: 1.76s\n",
            "100:\ttest: 0.9930556\tbest: 0.9933862 (18)\ttotal: 698ms\tremaining: 1.38s\n",
            "200:\ttest: 0.9937169\tbest: 0.9937169 (112)\ttotal: 1.84s\tremaining: 907ms\n",
            "299:\ttest: 0.9940476\tbest: 0.9940476 (230)\ttotal: 2.43s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.994047619\n",
            "bestIteration = 230\n",
            "\n",
            "Shrink model to first 231 iterations.\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.90      0.94        42\n",
            "           1       0.95      0.99      0.97        72\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.95      0.95       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhIAAAHHCAYAAADqJrG+AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAUR5JREFUeJzt3XdcU9f/P/BXQBKQEWTIqIIgylAcVauIoyp11NYBzjpw1dbiAldpnVSl1Spq66gL/Vit1dZaR1v3quLGamtFVCxVGS5AVMI6vz/8ma8xqElMTEhfTx/38SDn3tz7vjGBd97nnHslQggBIiIiIh1YGDsAIiIiKr+YSBAREZHOmEgQERGRzphIEBERkc6YSBAREZHOmEgQERGRzphIEBERkc6YSBAREZHOmEgQERGRzphI/Melpqaibdu2kMvlkEgk2Lx5s173f/XqVUgkEqxatUqv+y3P3nzzTbz55pvGDoNeoQEDBqBatWpGO/6qVasgkUhw9epVlfbZs2fD19cXlpaWqFevHgCgWrVqGDBgwCuPkcovJhIm4PLly/jggw/g6+sLa2trODg4IDQ0FPPnz8fDhw8NeuzIyEicO3cOM2bMwJo1a9CwYUODHu9VGjBgACQSCRwcHMp8HVNTUyGRSCCRSPDll19qvf8bN25g6tSpOHPmjB6iNQ59v/cWLVpUZtK4f/9+5Wv9eHFyckKTJk2wdu1aPZzJy5s5c6bWiXReXh6mTZuGunXrws7ODjY2NqhduzYmTJiAGzduGCZQPdm5cyfGjx+P0NBQJCYmYubMmcYOicqpCsYO4L9u+/bt6N69O2QyGfr374/atWujsLAQv//+O8aNG4e//voLS5cuNcixHz58iKSkJHz66acYPny4QY7h7e2Nhw8fwsrKyiD7f5EKFSrgwYMH2Lp1K3r06KGybu3atbC2tkZBQYFO+75x4wamTZuGatWqKb/NaWLnzp06HU/fDPHeW7RoEVxcXJ75jXbkyJFo1KgRAOD27dv4/vvv0bdvX+Tk5CAqKuplT+mlzJw5E926dUOXLl002v7KlSsICwtDeno6unfvjqFDh0IqleLs2bNYsWIFfvrpJ1y8eNGwQWuoX79+6NWrF2QymbJt7969sLCwwIoVKyCVSpXtKSkpsLDgd0zSHBMJI0pLS0OvXr3g7e2NvXv3wsPDQ7kuKioKly5dwvbt2w12/Js3bwIAHB0dDXYMiUQCa2trg+3/RWQyGUJDQ/Hdd9+pJRLr1q1Dx44d8eOPP76SWB48eICKFSuq/NI2FmO995o3b45u3bopHw8bNgy+vr5Yt26d0RMJbRQXFyM8PBxZWVnYv38/mjVrprJ+xowZ+OKLL4wUnTpLS0tYWlqqtGVnZ8PGxkbt/fhksvGyiouLUVpaahLveTIgQUbz4YcfCgDi8OHDGm1fVFQk4uLihK+vr5BKpcLb21vExsaKgoICle28vb1Fx44dxaFDh0SjRo2ETCYTPj4+YvXq1cptpkyZIgCoLN7e3kIIISIjI5U/P+nxc560c+dOERoaKuRyubC1tRU1a9YUsbGxyvVpaWkCgEhMTFR53p49e0SzZs1ExYoVhVwuF506dRLnz58v83ipqakiMjJSyOVy4eDgIAYMGCDu37//wtcrMjJS2NrailWrVgmZTCbu3r2rXHf8+HEBQPz4448CgJg9e7Zy3e3bt8WYMWNE7dq1ha2trbC3txft27cXZ86cUW6zb98+tdfvyfNs2bKlqFWrljh58qRo3ry5sLGxEaNGjVKua9mypXJf/fv3FzKZTO3827ZtKxwdHcX169dfeK7a0va9t3LlStGqVSvh6uoqpFKpCAwMFIsWLVLZxtvbW+31eHyej1+vjRs3qu27du3aokWLFiptmr7XhRBi4cKFIigoSEilUuHh4SE++ugjlf9rIYS4ePGiCA8PF25ubkImk4nXXntN9OzZU+Tk5AghRJn/l5GRkc98PdavXy8AiBkzZmjw6pX9mZo9e7YICQkRTk5OwtraWrz++utlvj4v+owJIcSCBQtEUFCQsLGxEY6OjqJBgwZi7dq1yvWJiYkCgEhLS3vm+T5+73p7e6ud+927d8WoUaNElSpVhFQqFdWrVxeff/65KCkpUW7z+LM+e/ZskZCQIHx9fYWFhYVITk7W6DWi8osVCSPaunUrfH190bRpU422HzJkCFavXo1u3bphzJgxOHbsGOLj4/H333/jp59+Utn20qVL6NatGwYPHozIyEisXLkSAwYMQIMGDVCrVi2Eh4fD0dER0dHR6N27N95++23Y2dlpFf9ff/2Fd955B3Xq1EFcXBxkMhkuXbqEw4cPP/d5u3fvRocOHeDr64upU6fi4cOH+OqrrxAaGorTp0+rDUrr0aMHfHx8EB8fj9OnT2P58uWoXLmyxt/4wsPD8eGHH2LTpk0YNGgQgEfViICAALz++utq21+5cgWbN29G9+7d4ePjg6ysLHzzzTdo2bIlzp8/D09PTwQGBiIuLg6TJ0/G0KFD0bx5cwBQ+b+8ffs2OnTogF69eqFv375wc3MrM7758+dj7969iIyMRFJSEiwtLfHNN99g586dWLNmDTw9PTU6T21o+95bvHgxatWqhU6dOqFChQrYunUrPvroI5SWliorCfPmzcOIESNgZ2eHTz/9FADUzvnevXu4desWAODOnTtYt24d/vzzT6xYsUJlO03f61OnTsW0adMQFhaGYcOGISUlBYsXL8aJEydw+PBhWFlZobCwEO3atYNCocCIESPg7u6O69evY9u2bcjJyYFcLseaNWswZMgQvPHGGxg6dCgAoHr16s98PbZs2QLgUZeBrubPn49OnTqhT58+KCwsxPr169G9e3ds27YNHTt2BKDZZ2zZsmUYOXIkunXrhlGjRqGgoABnz57FsWPH8N5775V57DVr1mDp0qU4fvw4li9fDgDPfC88ePAALVu2xPXr1/HBBx/Ay8sLR44cQWxsLDIyMjBv3jyV7RMTE1FQUIChQ4dCJpPByclJ59eIygljZzL/Vbm5uQKA6Ny5s0bbnzlzRgAQQ4YMUWkfO3asACD27t2rbHv8zfDgwYPKtuzsbCGTycSYMWOUbU9+g3iSphWJhIQEAUDcvHnzmXGXVZGoV6+eqFy5srh9+7ay7Y8//hAWFhaif//+ascbNGiQyj67du0qnJ2dn3nMJ8/D1tZWCCFEt27dRJs2bYQQQpSUlAh3d3cxbdq0Ml+DgoIClW9aj89DJpOJuLg4ZduJEyfKrLYI8ajqAEAsWbKkzHVPViSEEGLHjh0CgJg+fbq4cuWKsLOzE126dHnhOepC2/eeEEI8ePBAra1du3bC19dXpa1WrVpq5ybEsys4FhYWat/qNX2vZ2dnC6lUKtq2bavy//X1118LAGLlypVCCCGSk5OfWQ15kq2t7XOrEE+qX7++kMvlGm0rRNmfqadf08LCQlG7dm3RunVrZZsmn7HOnTuLWrVqPff4T1ckHsf0+PPxpKcrEp999pmwtbUVFy9eVNnu448/FpaWliI9PV0I8X+fdQcHB5Gdnf3ceMi8cESNkeTl5QEA7O3tNdr+l19+AQDExMSotI8ZMwYA1Pqzg4KClN+SAcDV1RX+/v64cuWKzjE/7fHYip9//hmlpaUaPScjIwNnzpzBgAEDVL6p1KlTB2+99ZbyPJ/04Ycfqjxu3rw5bt++rXwNNfHee+9h//79yMzMxN69e5GZmfnMb2symUw52KykpAS3b9+GnZ0d/P39cfr0aY2PKZPJMHDgQI22bdu2LT744APExcUhPDwc1tbW+OabbzQ+lja0fe8BgI2NjfLn3Nxc3Lp1Cy1btsSVK1eQm5ur8X4mT56MXbt2YdeuXfj+++/Ru3dvfPrpp5g/f75yG03f67t370ZhYSFGjx6tMjjw/fffh4ODg3I7uVwOANixYwcePHigcazPk5eXp9XrV5YnX9O7d+8iNzcXzZs3V3mPafIZc3R0xLVr13DixImXiudZNm7ciObNm6NSpUq4deuWcgkLC0NJSQkOHjyosn1ERARcXV0NEguZJiYSRuLg4ADgUalXE//88w8sLCzg5+en0u7u7g5HR0f8888/Ku1eXl5q+6hUqRLu3r2rY8TqevbsidDQUAwZMgRubm7o1asXNmzY8Nyk4nGc/v7+ausCAwNx69Yt3L9/X6X96XOpVKkSAGh1Lm+//Tbs7e3x/fffY+3atWjUqJHaa/lYaWkpEhISUKNGDchkMri4uMDV1RVnz57V6o/ma6+9ptUgsy+//BJOTk44c+YMFixYgMqVK7/wOTdv3kRmZqba8nggbVm0fe8BwOHDhxEWFgZbW1s4OjrC1dUVn3zyCQBo9ZoEBwcjLCwMYWFh6NGjB7799lu88847+Pjjj5Uxa/pef9Z7SSqVwtfXV7nex8cHMTExWL58OVxcXNCuXTssXLhQq7if5uDgoNXrV5Zt27ahSZMmsLa2hpOTE1xdXbF48WKVuDT5jE2YMAF2dnZ44403UKNGDURFRb2we1Ebqamp+O233+Dq6qqyhIWFAXg0aPNJPj4+ejs2lQ9MJIzEwcEBnp6e+PPPP7V6nkQi0Wi7p0doPyaE0PkYJSUlKo9tbGxw8OBB7N69G/369cPZs2fRs2dPvPXWW2rbvoyXOZfHZDIZwsPDsXr1avz000/PrEYAj6YBxsTEoEWLFvj222+xY8cO7Nq1C7Vq1dK48gKofuPURHJysvKX8rlz5zR6TqNGjeDh4aG2PJ5iWRZt33uXL19GmzZtcOvWLcydOxfbt2/Hrl27EB0dDQBavSZladOmDQoKCnD8+HGVdk3f65qYM2cOzp49i08++QQPHz7EyJEjUatWLVy7dk2n/QUEBCA3Nxf//vuvTs8/dOgQOnXqBGtrayxatAi//PILdu3ahffee0/lfa3JZywwMBApKSlYv349mjVrhh9//BHNmjXDlClTdIrtaaWlpXjrrbeUlaSnl4iICJXttX3fU/nHwZZG9M4772Dp0qVISkpCSEjIc7f19vZGaWkpUlNTERgYqGzPyspCTk4OvL299RZXpUqVkJOTo9b+dNUDACwsLNCmTRu0adMGc+fOxcyZM/Hpp59i3759ym8sT58H8Giu+tMuXLgAFxcX2NravvxJlOG9997DypUrYWFhgV69ej1zux9++AGtWrVSGwCYk5MDFxcX5WN9/qG7f/8+Bg4ciKCgIDRt2hSzZs1C165dn5sQAI+uhVHWhaNe9Mtcm/fe1q1boVAosGXLFpXq0L59+9S21eU1KS4uBgDk5+cD0Py9/uR7ydfXV7ldYWEh0tLS1N5/wcHBCA4OxsSJE3HkyBGEhoZiyZIlmD59utaxv/vuu/juu+/w7bffIjY2Vutz/vHHH2FtbY0dO3aoTLdMTExU21aTz5itrS169uyJnj17orCwEOHh4ZgxYwZiY2Nfevp19erVkZ+fX+bnmQhgRcKoxo8fD1tbWwwZMgRZWVlq6y9fvqzsO3777bcBQG2E9Ny5cwFAOcpbH6pXr47c3FycPXtW2ZaRkaE2M+TOnTtqz318YSaFQlHmvj08PFCvXj2sXr1aJVn5888/sXPnTuV5GkKrVq3w2Wef4euvv4a7u/szt7O0tFSrdmzcuBHXr19XaXuc8JSVdGlrwoQJSE9Px+rVqzF37lxUq1YNkZGRz3wdHwsNDVV2FTy5hIaGPvd52rz3HleEnnxNcnNzy/yjZ2trq/XrsW3bNgBA3bp1AWj+Xg8LC4NUKsWCBQtUYluxYgVyc3OV2+Xl5SmTlceCg4NhYWGh8vpqE3u3bt0QHByMGTNmICkpSW39vXv3lDNXymJpaQmJRKJSubt69aralTU1+Yzdvn1bZb1UKkVQUBCEECgqKtLofJ6nR48eSEpKwo4dO9TW5eTkqL229N/DioQRVa9eHevWrUPPnj0RGBiocnXBI0eOYOPGjcorBNatWxeRkZFYunQpcnJy0LJlSxw/fhyrV69Gly5d0KpVK73F1atXL0yYMAFdu3bFyJEj8eDBAyxevBg1a9ZUGQgWFxeHgwcPomPHjvD29kZ2djYWLVqEKlWqqF2g50mzZ89Ghw4dEBISgsGDByunf8rlckydOlVv5/E0CwsLTJw48YXbvfPOO4iLi8PAgQPRtGlTnDt3DmvXrlX51gs8+v9zdHTEkiVLYG9vD1tbWzRu3FjrPuK9e/di0aJFmDJlinI6amJiIt58801MmjQJs2bN0mp/mtDmvde2bVtIpVK8++67+OCDD5Cfn49ly5ahcuXKyMjIUNlvgwYNsHjxYkyfPh1+fn6oXLkyWrdurVx/6NAh5ZVE79y5gy1btuDAgQPo1asXAgICAGj+Xnd1dUVsbCymTZuG9u3bo1OnTkhJScGiRYvQqFEj9O3bV/n6Dh8+HN27d0fNmjVRXFyMNWvWwNLSUqUs36BBA+zevRtz586Fp6cnfHx80Lhx4zJfPysrK2zatAlhYWFo0aIFevTogdDQUFhZWeGvv/7CunXrUKlSJcyYMaPM53fs2BFz585F+/bt8d577yE7OxsLFy6En5+fSgKvyWesbdu2cHd3R2hoKNzc3PD333/j66+/RseOHV96QCgAjBs3Dlu2bME777yjnEJ+//59nDt3Dj/88AOuXr2qUqmj/yAjzhih/+/ixYvi/fffF9WqVRNSqVTY29uL0NBQ8dVXX6lcgKeoqEhMmzZN+Pj4CCsrK1G1atXnXpDqaU9PO3zW9E8hHl0Ep3bt2kIqlQp/f3/x7bffqk3/3LNnj+jcubPw9PQUUqlUeHp6it69e6tME3vWBal2794tQkNDhY2NjXBwcBDvvvvuMy9I9fTUt7KmspXlWdPbnvSs6Z9jxowRHh4ewsbGRoSGhoqkpKQyp23+/PPPIigoSFSoUKHMC1KV5cn95OXlCW9vb/H666+LoqIile2io6OFhYWFSEpKeu45vAxN33tbtmwRderUEdbW1qJatWriiy++ECtXrlT7f8jMzBQdO3YU9vb2ZV6Q6slFKpWKgIAAMWPGDFFYWKgSl6bvdSEeTfcMCAgQVlZWws3NTQwbNkzlglRXrlwRgwYNEtWrVxfW1tbCyclJtGrVSuzevVtlPxcuXBAtWrQQNjY2L7wg1WN3794VkydPFsHBwaJixYrC2tpa1K5dW8TGxoqMjAzldmVN/1yxYoWoUaOGkMlkIiAgQCQmJur0Gfvmm29EixYthLOzs5DJZKJ69epi3LhxIjc3V7nNy0z/FEKIe/fuidjYWOHn5yekUqlwcXERTZs2FV9++aXy/+55v0/IvEmE0GLEGhEREdETOEaCiIiIdMZEgoiIiHTGRIKIiIh0xkSCiIiIdMZEgoiIiHTGRIKIiIh0xkSCiIiIdGaWV7YctF6zGx4R/dfM7Rxk7BCITI6jTdk3BtQnm/rD9bKfh8lf62U/+sSKBBERkRmqVq0aJBKJ2hIVFQUAKCgoQFRUFJydnWFnZ4eIiIgy773zIkwkiIiIDE1ioZ9FCydOnEBGRoZy2bVrFwCge/fuAIDo6Ghs3boVGzduxIEDB3Djxg2Eh4drfWpm2bVBRERkUrS4Tb2+uLq6qjz+/PPPUb16dbRs2RK5ublYsWIF1q1bp7yxXmJiIgIDA3H06FE0adJE4+OwIkFERGRoeqpIKBQK5OXlqSyPbyn/PIWFhfj2228xaNAgSCQSnDp1CkVFRQgLC1NuExAQAC8vLyQlJWl1akwkiIiIyon4+HjI5XKVJT4+/oXP27x5M3JycjBgwAAAQGZmJqRSKRwdHVW2c3NzQ2ZmplYxsWuDiIjI0PTUtREbG4uYmBiVNplM9sLnrVixAh06dICnp6de4ngSEwkiIiJD03Kg5LPIZDKNEocn/fPPP9i9ezc2bdqkbHN3d0dhYSFycnJUqhJZWVlwd3fXav/s2iAiIjJjiYmJqFy5Mjp27Khsa9CgAaysrLBnzx5lW0pKCtLT0xESEqLV/lmRICIiMjQjzNoAgNLSUiQmJiIyMhIVKvzfn3y5XI7BgwcjJiYGTk5OcHBwwIgRIxASEqLVjA2AiQQREZHh6alrQ1u7d+9Geno6Bg0apLYuISEBFhYWiIiIgEKhQLt27bBo0SKtjyERQgh9BGtKeIlsorLxEtlE6l7JJbKbTNDLfh4e/UIv+9EnViSIiIgMzUhdG68CEwkiIiJDM1LXxqtgvmdGREREBseKBBERkaGxa4OIiIh0ZsZdG0wkiIiIDM2MKxLmmyIRERGRwbEiQUREZGjs2iAiIiKdmXEiYb5nRkRERAbHigQREZGhWZjvYEsmEkRERIbGrg0iIiIidaxIEBERGZoZX0eCiQQREZGhsWuDiIiISB0rEkRERIbGrg0iIiLSmRl3bTCRICIiMjQzrkiYb4pEREREBseKBBERkaGxa4OIiIh0xq4NIiIiInWsSBARERkauzaIiIhIZ+zaICIiIlLHigQREZGhsWuDiIiIdGbGiYT5nhkREREZHCsSREREhmbGgy2ZSBARERmaGXdtMJEgIiIyNDOuSJhvikREREQGx4oEERGRobFrg4iIiHTGrg0iIiIidaxIEBERGZjEjCsSTCSIiIgMzJwTCXZtEBERkc5YkSAiIjI08y1IMJEgIiIyNHZtEBEREZWBiQQREZGBSSQSvSzaun79Ovr27QtnZ2fY2NggODgYJ0+eVK4XQmDy5Mnw8PCAjY0NwsLCkJqaqtUxmEgQEREZmDESibt37yI0NBRWVlb49ddfcf78ecyZMweVKlVSbjNr1iwsWLAAS5YswbFjx2Bra4t27dqhoKBA4+NwjAQREZGBGWOMxBdffIGqVasiMTFR2ebj46P8WQiBefPmYeLEiejcuTMA4H//+x/c3NywefNm9OrVS6PjsCJBRERUTigUCuTl5aksCoWizG23bNmChg0bonv37qhcuTLq16+PZcuWKdenpaUhMzMTYWFhyja5XI7GjRsjKSlJ45iYSBARERmaRD9LfHw85HK5yhIfH1/mIa9cuYLFixejRo0a2LFjB4YNG4aRI0di9erVAIDMzEwAgJubm8rz3NzclOs0wa4NIiIiA9NX10ZsbCxiYmJU2mQyWZnblpaWomHDhpg5cyYAoH79+vjzzz+xZMkSREZG6iUegBUJIiKickMmk8HBwUFleVYi4eHhgaCgIJW2wMBApKenAwDc3d0BAFlZWSrbZGVlKddpwiQSCUtLS2RnZ6u13759G5aWlkaIiIiISH+MMWsjNDQUKSkpKm0XL16Et7c3gEcDL93d3bFnzx7l+ry8PBw7dgwhISEaH8ckujaEEGW2KxQKSKXSVxwNERGRfhlj1kZ0dDSaNm2KmTNnokePHjh+/DiWLl2KpUuXKmMaPXo0pk+fjho1asDHxweTJk2Cp6cnunTpovFxjJpILFiwAMCjk1m+fDns7OyU60pKSnDw4EEEBAQYKzwiIqJyq1GjRvjpp58QGxuLuLg4+Pj4YN68eejTp49ym/Hjx+P+/fsYOnQocnJy0KxZM/z222+wtrbW+DgS8axywCvweD7rP//8gypVqqh0Y0ilUlSrVg1xcXFo3LixVvsdtP6cXuMkMhdzOwe9eCOi/xhHG8N3oTv3/04v+7n9v9562Y8+GbUikZaWBgBo1aoVNm3apHK1LSIiIrNhvvfsMo0xEvv27TN2CERERKQDk0gkSkpKsGrVKuzZswfZ2dkoLS1VWb93714jRUZERPTyzPk24iaRSIwaNQqrVq1Cx44dUbt2bbN+wYmI6L/HnP+umUQisX79emzYsAFvv/22sUMhIiLSO3NOJEziglRSqRR+fn7GDoOIiIi0ZBKJxJgxYzB//vxnXpiKiIioXNPTTbtMkUl0bfz+++/Yt28ffv31V9SqVQtWVlYq6zdt2mSkyIiIiF6eOXdtmEQi4ejoiK5duxo7DCIiItKSSSQSiYmJxg6BiIjIYFiRICIiIp0xkXgFfvjhB2zYsAHp6ekoLCxUWXf69GkjRUVERETPYxKzNhYsWICBAwfCzc0NycnJeOONN+Ds7IwrV66gQ4cOxg6PiIjopUgkEr0spsgkEolFixZh6dKl+OqrryCVSjF+/Hjs2rULI0eORG5urrHDIyIiejlmPP3TJBKJ9PR0NG3aFABgY2ODe/fuAQD69euH777Tz61XiYiISP9MIpFwd3fHnTt3AABeXl44evQogEe3GedFqoiIqLxj14aBtW7dGlu2bAEADBw4ENHR0XjrrbfQs2dPXl+CiIjKPXNOJExi1sbSpUuVtw6PioqCs7Mzjhw5gk6dOuGDDz4wcnREREQvx1STAH0wiUTCwsICFhb/Vxzp1asXevXqZcSIiIiISBMmkUgAQE5ODo4fP47s7GxldeKx/v37GykqIiIiPTDfgoRpJBJbt25Fnz59kJ+fDwcHB5USkEQiYSJBRETlmjl3bZjEYMsxY8Zg0KBByM/PR05ODu7evatcHs/mICIiItNjEhWJ69evY+TIkahYsaKxQyEdvOnnhFZ+TnCxlQIArucqsPWvLJzLyAcAOFhXQI967qjlZgdrK0tk5imw7Xw2Tl3LM2bYREa1euUyLFqQgJ7v9UPM+Fhjh0MGZs4VCZNIJNq1a4eTJ0/C19fX2KGQDu4+KMIPf2Qh654CEgkQWq0SRjTzxtQdl3AjT4EhTaqgopUlFhz6B/mKYjT2dsSwpl6I23kJ6TkFxg6f6JU7/+c5/PTDBvjV9Dd2KPSKMJEwsI4dO2LcuHE4f/48goODYWVlpbK+U6dORoqMNPHHjXsqjzedy8Kbfk6o7lIRN/IU8HOuiDWnbiDtzkMAwLbzN9HW3wXeTjZMJOg/58GD+5j8yXh8MnkaEpd9Y+xwiF6aSSQS77//PgAgLi5ObZ1EIkFJScmrDol0JJEAjarKIatggcu3HgAALt1+gDeqynH2xj08KCxBIy85rCwtkJJ938jREr16s2dOR2jzlnijSVMmEv8hrEgY2NPTPan8eU0uw6dh1WFlaQFFcSm+/j0dN/IUAIDFh9MxrKkXvgoPQnGpQGFxKb7+/R9k5xe+YK9E5mXnb78g5cJ5JK7dYOxQ6FUz3zzCNBKJl6FQKKBQKFTaSooKYWklNVJE/02Z9woxdccl2FhZoGFVOYY0roIv9l7BjTwFuga7oaLUErP3XUG+ogT1X3PAsKZeiN9zGddzFS/eOZEZyMrMwNxZ8fhqyXLIZDJjh0OkNyaRSCxYsKDMdolEAmtra/j5+aFFixawtLRU2yY+Ph7Tpk1TaasX8SHqd/vIILFS2UpKhbLC8M/dAvg4VURYTWf8euEWwmq6YOIvF5UVin9zClDT1Ratazhjzckbxgyb6JW5cP4v3L1zG5G9uynbSkpKkHz6JH74fh0OHT9T5u84Mg/s2jCwhIQE3Lx5Ew8ePEClSpUAAHfv3kXFihVhZ2eH7Oxs+Pr6Yt++fahatarKc2NjYxETE6PSNuLn1FcWO5VNIgEqWFpAavnow/P0PVxLhYCFGX+wiJ7WsHEI1v3ws0rbZ5M/hbePD/oPHMIkwsyZcyJhEhekmjlzJho1aoTU1FTcvn0bt2/fxsWLF9G4cWPMnz8f6enpcHd3R3R0tNpzZTIZHBwcVBZ2a7xaEXXcUNO1IpxtrfCaXIaIOm7wr2yLo1dzkJmnQNY9Bfo3fA0+TjZwtZOinb8LgtztcJrXkaD/EFtbW1T3q6Gy2NjYQC53RHW/GsYOjwxMItHPYopMoiIxceJE/Pjjj6hevbqyzc/PD19++SUiIiJw5coVzJo1CxEREUaMkp7FwboChjSpCrl1BTwsKsW1nALM3X8V57MeXZAq4cBVdKvrjpEtvGFdwRLZ9xRYcewazmXce8GeiYjI1JlEIpGRkYHi4mK19uLiYmRmZgIAPD09ce8e//CYosTj15+7Pju/EIsOp7+iaIjKj8UrVhs7BHpF2LVhYK1atcIHH3yA5ORkZVtycjKGDRuG1q1bAwDOnTsHHx8fY4VIRESkM3Pu2jCJRGLFihVwcnJCgwYNIJPJIJPJ0LBhQzg5OWHFihUAADs7O8yZM8fIkRIREdGTTKJrw93dHbt27cKFCxdw8eJFAIC/vz/8/f/vOvStWrUyVnhEREQvxZy7NkwikXgsICAAAQEBxg6DiIhIr8w4jzBeIhETE4PPPvsMtra2ateBeNrcuXNfUVRERESkDaMlEsnJySgqKlL+/CzmXA4iIqL/BgsL8/1bZrREYt++fWX+TEREZG7M+TuxSczaICIiovLJaBWJ8PBwjbfdtGmTASMhIiIyLHPupjdaRUIul2u8EBERlWfGuCDV1KlTIZFIVJYnZ0YWFBQgKioKzs7OsLOzQ0REBLKysrQ+N6NVJBITE411aCIiolfKWBWJWrVqYffu3crHFSr835/96OhobN++HRs3boRcLsfw4cMRHh6Ow4cPa3UMk7qOBBEREelPhQoV4O7urtaem5uLFStWYN26dcpbUSQmJiIwMBBHjx5FkyZNND+G3qJ9ST/88AM2bNiA9PR0FBYWqqw7ffq0kaIiIiJ6efqqSCgUCigUCpW2x7eWKEtqaio8PT1hbW2NkJAQxMfHw8vLC6dOnUJRURHCwsKU2wYEBMDLywtJSUlaJRImMWtjwYIFGDhwINzc3JCcnIw33ngDzs7OuHLlCjp06GDs8IiIiF6KvsZIxMfHq40jjI+PL/OYjRs3xqpVq/Dbb79h8eLFSEtLQ/PmzXHv3j1kZmZCKpXC0dFR5Tlubm7Ku25ryiQqEosWLcLSpUvRu3dvrFq1CuPHj4evry8mT56MO3fuGDs8IiIikxAbG6t2NehnVSOe/CJep04dNG7cGN7e3tiwYQNsbGz0FpNJVCTS09PRtGlTAICNjQ3u3bsHAOjXrx++++47Y4ZGRET00p6ePaHrIpPJ4ODgoLI8K5F4mqOjI2rWrIlLly7B3d0dhYWFyMnJUdkmKyurzDEVz2MSiYS7u7uy8uDl5YWjR48CANLS0iCEMGZoREREL80Y0z+flp+fj8uXL8PDwwMNGjSAlZUV9uzZo1yfkpKC9PR0hISEaLVfk+jaaN26NbZs2YL69etj4MCBiI6Oxg8//ICTJ09qdeEqIiIiemTs2LF499134e3tjRs3bmDKlCmwtLRE7969IZfLMXjwYMTExMDJyQkODg4YMWIEQkJCtBpoCZhIIrF06VKUlpYCAKKiouDi4oLDhw+jU6dO+PDDD40cHRER0csxxnUkrl27ht69e+P27dtwdXVFs2bNcPToUbi6ugIAEhISYGFhgYiICCgUCrRr1w6LFi3S+jgSYSJ9BwUFBTh79iyys7OVSQXw6MV/9913tdrXoPXn9B0ekVmY2znI2CEQmRxHG0uDH6PhdP3cnPLkxFZ62Y8+mURF4rfffkO/fv1w+/ZttXUSiQQlJSVGiIqIiIhexCQGW44YMQI9evRARkYGSktLVRYmEUREVN7pa9aGKTKJikRWVhZiYmLg5uZm7FCIiIj0zkRzAL0wiYpEt27dsH//fmOHQUREZBCsSBjY119/je7du+PQoUMIDg6GlZWVyvqRI0caKTIiIiJ6HpNIJL777jvs3LkT1tbW2L9/v0rWJZFImEgQEVG5ZqLFBL0wiUTi008/xbRp0/Dxxx/DwsIkeluIiIj0xlS7JfTBJP5qFxYWomfPnkwiiIiIyhmT+MsdGRmJ77//3thhEBERGYQp3GvDUEyia6OkpASzZs3Cjh07UKdOHbXBlnPnzjVSZERERC/PnLs2TCKROHfuHOrXrw8A+PPPP1XWmfOLT0REVN6ZRCKxb59+rkFORERkisz5O7FJJBJERETmzJyr6yYx2JKIiIjKJ1YkiIiIDMycKxJMJIiIiAzMjPMIJhJERESGZs4VCY6RICIiIp2xIkFERGRgZlyQYCJBRERkaOzaICIiIioDKxJEREQGZsYFCSYSREREhmZhxpkEuzaIiIhIZ6xIEBERGZgZFySYSBARERmaOc/aYCJBRERkYBbmm0dwjAQRERHpjhUJIiIiA2PXBhEREenMjPMIdm0QERGR7liRICIiMjAJzLckwUSCiIjIwMx51oZGicTZs2c13mGdOnV0DoaIiIjKF40SiXr16kEikUAIUeb6x+skEglKSkr0GiAREVF595+ftZGWlmboOIiIiMyWGecRmiUS3t7eho6DiIiIyiGdpn+uWbMGoaGh8PT0xD///AMAmDdvHn7++We9BkdERGQOLCQSvSymSOtEYvHixYiJicHbb7+NnJwc5ZgIR0dHzJs3T9/xERERlXsSiX4WU6R1IvHVV19h2bJl+PTTT2Fpaalsb9iwIc6dO6fX4IiIiMyBRCLRy2KKtE4k0tLSUL9+fbV2mUyG+/fv6yUoIiIiKh+0TiR8fHxw5swZtfbffvsNgYGB+oiJiIjIrLBr4wkxMTGIiorC999/DyEEjh8/jhkzZiA2Nhbjx483RIxERETlmikMtvz8888hkUgwevRoZVtBQQGioqLg7OwMOzs7REREICsrS6v9an2J7CFDhsDGxgYTJ07EgwcP8N5778HT0xPz589Hr169tN0dERERGdiJEyfwzTffqF19Ojo6Gtu3b8fGjRshl8sxfPhwhIeH4/DhwxrvW6fpn3369EFqairy8/ORmZmJa9euYfDgwbrsioiIyOxJ9LToIj8/H3369MGyZctQqVIlZXtubi5WrFiBuXPnonXr1mjQoAESExNx5MgRHD16VOP963wb8ezsbJw6dQopKSm4efOmrrshIiIye/qataFQKJCXl6eyKBSK5x47KioKHTt2RFhYmEr7qVOnUFRUpNIeEBAALy8vJCUlaXxuWicS9+7dQ79+/eDp6YmWLVuiZcuW8PT0RN++fZGbm6vt7oiIiEhD8fHxkMvlKkt8fPwzt1+/fj1Onz5d5jaZmZmQSqVwdHRUaXdzc0NmZqbGMWmdSAwZMgTHjh3D9u3bkZOTg5ycHGzbtg0nT57EBx98oO3uiIiIzJ6FRD9LbGwscnNzVZbY2Ngyj/nvv/9i1KhRWLt2LaytrQ12bloPtty2bRt27NiBZs2aKdvatWuHZcuWoX379noNjoiIyBzo62JSMpkMMplMo21PnTqF7OxsvP7668q2kpISHDx4EF9//TV27NiBwsJC5OTkqFQlsrKy4O7urnFMWicSzs7OkMvlau1yuVxlEAcREREZT5s2bdSuOD1w4EAEBARgwoQJqFq1KqysrLBnzx5EREQAAFJSUpCeno6QkBCNj6N1IjFx4kTExMRgzZo1yowlMzMT48aNw6RJk7TdHRERkdkzxsWk7O3tUbt2bZU2W1tbODs7K9sHDx6MmJgYODk5wcHBASNGjEBISAiaNGmi8XE0SiTq16+vUpZJTU2Fl5cXvLy8AADp6emQyWS4efMmx0kQERE9xVTvk5GQkAALCwtERERAoVCgXbt2WLRokVb70CiR6NKliy7xERERER4NlDQF+/fvV3lsbW2NhQsXYuHChTrvU6NEYsqUKTofgIiIiMyX1mMkiIiISDum2rWhD1onEiUlJUhISMCGDRuQnp6OwsJClfV37tzRW3BERETmwHzTCB0uSDVt2jTMnTsXPXv2RG5uLmJiYhAeHg4LCwtMnTrVACESERGRqdI6kVi7di2WLVuGMWPGoEKFCujduzeWL1+OyZMna3WTDyIiov8KU7iNuKFonUhkZmYiODgYAGBnZ6e8v8Y777yD7du36zc6IiIiMyCR6GcxRVonElWqVEFGRgYAoHr16ti5cyeAR/c61/SynURERGQetE4kunbtij179gAARowYgUmTJqFGjRro378/Bg0apPcAiYiIyjt93UbcFGk9a+Pzzz9X/tyzZ094e3vjyJEjqFGjBt599129BkdERGQOTDQH0AutKxJPa9KkCWJiYtC4cWPMnDlTHzERERFROfHSicRjGRkZvGkXERFRGcx51gavbElERGRgJpoD6AUTCSIiIgMz1YGS+qC3rg0iIiL679G4IhETE/Pc9Tdv3nzpYPRlUbdgY4dAZJIqNRpu7BCITM7D5K8Nfgxz/taucSKRnJz8wm1atGjxUsEQERGZI3Pu2tA4kdi3b58h4yAiIqJyiIMtiYiIDMzCfAsSTCSIiIgMzZwTCXMe/0FEREQGxooEERGRgXGwJREREemMXRtPOXToEPr27YuQkBBcv34dALBmzRr8/vvveg2OiIiITJvWicSPP/6Idu3awcbGBsnJyVAoFACA3Nxc3v2TiIioDBKJfhZTpHUiMX36dCxZsgTLli2DlZWVsj00NBSnT5/Wa3BERETmgHf/fEJKSkqZV7CUy+XIycnRR0xERERmxZynSGp9bu7u7rh06ZJa+++//w5fX1+9BEVERETlg9aJxPvvv49Ro0bh2LFjkEgkuHHjBtauXYuxY8di2LBhhoiRiIioXDPnMRJad218/PHHKC0tRZs2bfDgwQO0aNECMpkMY8eOxYgRIwwRIxERUblmquMb9EHrREIikeDTTz/FuHHjcOnSJeTn5yMoKAh2dnaGiI+IiIhMmM4XpJJKpQgKCtJnLERERGbJjAsS2icSrVq1eu6lPvfu3ftSAREREZkbc76ypdaJRL169VQeFxUV4cyZM/jzzz8RGRmpr7iIiIioHNA6kUhISCizferUqcjPz3/pgIiIiMyNOQ+21Ns1Mvr27YuVK1fqa3dERERmw5ynf+otkUhKSoK1tbW+dkdERETlgNZdG+Hh4SqPhRDIyMjAyZMnMWnSJL0FRkREZC442PIJcrlc5bGFhQX8/f0RFxeHtm3b6i0wIiIicyGB+WYSWiUSJSUlGDhwIIKDg1GpUiVDxURERGRWzLkiodUYCUtLS7Rt25Z3+SQiIiIAOgy2rF27Nq5cuWKIWIiIiMyShUQ/iynSOpGYPn06xo4di23btiEjIwN5eXkqCxEREamSSCR6WbSxePFi1KlTBw4ODnBwcEBISAh+/fVX5fqCggJERUXB2dkZdnZ2iIiIQFZWltbnpnEiERcXh/v37+Ptt9/GH3/8gU6dOqFKlSqoVKkSKlWqBEdHR46bICIiMhFVqlTB559/jlOnTuHkyZNo3bo1OnfujL/++gsAEB0dja1bt2Ljxo04cOAAbty4oTYzUxMSIYTQZENLS0tkZGTg77//fu52LVu21DoIfSsoNnYERKapUqPhxg6ByOQ8TP7a4MeYc0A/QwLGtPR9qec7OTlh9uzZ6NatG1xdXbFu3Tp069YNAHDhwgUEBgYiKSkJTZo00XifGs/aeJxvmEKiQEREVJ4Y+6qUJSUl2LhxI+7fv4+QkBCcOnUKRUVFCAsLU24TEBAALy8vwyUSALTunyEiIiL9USgUUCgUKm0ymQwymazM7c+dO4eQkBAUFBTAzs4OP/30E4KCgnDmzBlIpVI4OjqqbO/m5obMzEytYtJqsGXNmjXh5OT03IWIiIhUWUgkelni4+Mhl8tVlvj4+Gce19/fH2fOnMGxY8cwbNgwREZG4vz583o9N60qEtOmTVO7siURERE9n76mbsbGxiImJkal7VnVCACQSqXw8/MDADRo0AAnTpzA/Pnz0bNnTxQWFiInJ0elKpGVlQV3d3etYtIqkejVqxcqV66s1QGIiIhIP57XjaGJ0tJSKBQKNGjQAFZWVtizZw8iIiIAACkpKUhPT0dISIhW+9Q4keD4CCIiIt0Y409obGwsOnToAC8vL9y7dw/r1q3D/v37sWPHDsjlcgwePBgxMTFwcnKCg4MDRowYgZCQEK0GWgI6zNogIiIi7VgY4aZd2dnZ6N+/PzIyMiCXy1GnTh3s2LEDb731FgAgISEBFhYWiIiIgEKhQLt27bBo0SKtj6PxdSTKE15HgqhsvI4EkbpXcR2JRUeu6mU/HzWtppf96JPWl8gmIiIiekyrwZZERESkPVO94ZY+MJEgIiIyMAsznrDArg0iIiLSGSsSREREBmbGBQkmEkRERIbGrg0iIiKiMrAiQUREZGBmXJBgIkFERGRo5lz+N+dzIyIiIgNjRYKIiMjAzPnGl0wkiIiIDMx80wgmEkRERAbH6Z9EREREZWBFgoiIyMDMtx7BRIKIiMjgzLhng10bREREpDtWJIiIiAyM0z+JiIhIZ+Zc/jfncyMiIiIDY0WCiIjIwNi1QURERDoz3zSCXRtERET0EliRICIiMjB2bRAREZHOzLn8z0SCiIjIwMy5ImHOSRIREREZGCsSREREBma+9QgmEkRERAZnxj0b7NogIiIi3bEiQUREZGAWZty5wUSCiIjIwNi1QURERFQGViSIiIgMTMKuDcNLTU3Fvn37kJ2djdLSUpV1kydPNlJUREREL8+cuzZMIpFYtmwZhg0bBhcXF7i7u6tcAUwikTCRICIiMlEmkUhMnz4dM2bMwIQJE4wdChERkd5x1oaB3b17F927dzd2GERERAZhzl0bJjFro3v37ti5c6exwyAiIjIIiUQ/iykyiYqEn58fJk2ahKNHjyI4OBhWVlYq60eOHGmkyIiIiOh5JEIIYewgfHx8nrlOIpHgypUrWu2voPhlIyIyT5UaDTd2CEQm52Hy1wY/xq6/b+llP28FuuhlP/pkEhWJtLQ0Y4dARERkMBYm2i2hDyYxRoKIiIj0Kz4+Ho0aNYK9vT0qV66MLl26ICUlRWWbgoICREVFwdnZGXZ2doiIiEBWVpZWxzGJikRMTEyZ7RKJBNbW1vDz80Pnzp3h5OT0iiMjIiJ6eca4suWBAwcQFRWFRo0aobi4GJ988gnatm2L8+fPw9bWFgAQHR2N7du3Y+PGjZDL5Rg+fDjCw8Nx+PBhjY9jEmMkWrVqhdOnT6OkpAT+/v4AgIsXL8LS0hIBAQFISUmBRCLB77//jqCgoBfuj2MkiMrGMRJE6l7FGIl9Kbf1sp9W/s46P/fmzZuoXLkyDhw4gBYtWiA3Nxeurq5Yt24dunXrBgC4cOECAgMDkZSUhCZNmmi0X5Po2ujcuTPCwsJw48YNnDp1CqdOncK1a9fw1ltvoXfv3rh+/TpatGiB6OhoY4dKRERkNAqFAnl5eSqLQqHQ6Lm5ubkAoKzunzp1CkVFRQgLC1NuExAQAC8vLyQlJWkck0kkErNnz8Znn30GBwcHZZtcLsfUqVMxa9YsVKxYEZMnT8apU6eMGCUREZFuJHr6Fx8fD7lcrrLEx8e/8PilpaUYPXo0QkNDUbt2bQBAZmYmpFIpHB0dVbZ1c3NDZmamxudmEmMkcnNzkZ2drdZtcfPmTeTl5QEAHB0dUVhYaIzwiIiIXoq+Zm3ExsaqjSuUyWQvfF5UVBT+/PNP/P777/oJ5AkmkUh07twZgwYNwpw5c9CoUSMAwIkTJzB27Fh06dIFAHD8+HHUrFnTiFESEREZl0wm0yhxeNLw4cOxbds2HDx4EFWqVFG2u7u7o7CwEDk5OSpViaysLLi7u2u8f5NIJL755htER0ejV69eKC5+NFKyQoUKiIyMREJCAoBH/TbLly83ZpikhVMnT2DVyhX4+/yfuHnzJhIWLETrNmEvfiKRmbiwfRq8PdUHxi35/iCiP9+AQeGh6NmhIeoFVIGDnQ3cm49Dbv5DI0RKr4IxZm0IITBixAj89NNP2L9/v9rFHxs0aAArKyvs2bMHERERAICUlBSkp6cjJCRE4+OYRCJhZ2eHZcuWISEhQXkVS19fX9jZ2Sm3qVevnpGiI108fPgA/v7+6BIegZhRnClA/z3N+s6G5RP17CA/T/yyZAQ27UoGAFS0tsKuI+ex68h5fDays7HCpFfEGPfJiIqKwrp16/Dzzz/D3t5eOe5BLpfDxsYGcrkcgwcPRkxMDJycnODg4IARI0YgJCRE4xkbgIkkEo/Z2dmhTp06xg6D9KBZ85Zo1rylscMgMppbd/NVHo8dWBuX02/i0KlUAMDX6/YDAJo3qPGqQyMjMMaFLRcvXgwAePPNN1XaExMTMWDAAABAQkICLCwsEBERAYVCgXbt2mHRokVaHcdoiUR4eDhWrVoFBwcHhIeHP3fbTZs2vaKoiIj0z6qCJXq93QgLvt1r7FDoP0STy0RZW1tj4cKFWLhwoc7HMVoiIZfLIfn/tR65XK7zfhQKhdocWmGp/WAUIiJD6dSqDhztbfDt1mPGDoWMxMJU7wGuB0ZLJBITE8v8WVvx8fGYNm2aStunk6Zg4uSpOu+TiEifIrs0xY7D55FxM9fYoZCRmG8aYWJjJHRR1pxaYclqBBGZBi+PSmjd2B+9xi4zdihEBmESV7bMyspCv3794OnpiQoVKsDS0lJleR6ZTAYHBweVhd0aRGQq+nUKQfade/j10F/GDoWMSaKnxQSZREViwIABSE9Px6RJk+Dh4aEcO0Hl14P795Genq58fP3aNVz4+2/I5XJ4eHoaMTKiV0cikaB/5yZYu+0YSkpKVda5OdvDzdkB1b1cAAC1a3ji3v0C/Jt5F3fzHhgjXDIgY1xH4lUxiUTi999/x6FDh3itCDPy119/YsjA/srHX856dC34Tp274rOZnxsrLKJXqnVjf3h5OGH15qNq64Z0a46JH76tfLx75aObEr4/eQ0HZVK5YhK3EQ8KCsLatWtRv359veyPtxEnKhtvI06k7lXcRvz4Ff0MtH3DV/dZjoZiEmMk5s2bh48//hhXr141dihERER6Z8ZDJEyja6Nnz5548OABqlevjooVK8LKykpl/Z07d4wUGRERET2PSSQS8+bNM3YIREREhmOq5QQ9MIlEIjIy0tghEBERGYw5z9owiTESAHD58mVMnDgRvXv3RnZ2NgDg119/xV9/ce41ERGVbxKJfhZTZBKJxIEDBxAcHIxjx45h06ZNyM9/dNe8P/74A1OmTDFydERERPQsJpFIfPzxx5g+fTp27doFqVSqbG/dujWOHlWff01ERFSemPOsDZNIJM6dO4euXbuqtVeuXBm3bt0yQkRERER6ZMaZhEkkEo6OjsjIyFBrT05OxmuvvWaEiIiIiEgTJpFI9OrVCxMmTEBmZiYkEglKS0tx+PBhjB07Fv3793/xDoiIiEyYRE//TJFJJBIzZ85EQEAAqlativz8fAQFBaF58+Zo2rQpJk6caOzwiIiIXoo5z9owiXttPPbvv//i3LlzuH//PurXrw8/Pz+d9sN7bRCVjffaIFL3Ku61cSb9nl72U8/LXi/70SeTuCAVAKxYsQIJCQlITU0FANSoUQOjR4/GkCFDjBwZERHRyzHRYoJemEQiMXnyZMydOxcjRoxASEgIACApKQnR0dFIT09HXFyckSMkIiJ6CWacSZhE14arqysWLFiA3r17q7R/9913GDFihNZTQNm1QVQ2dm0QqXsVXRt//Kufro26Vdm1UaaioiI0bNhQrb1BgwYoLmZWQERE5ZupzrjQB5OYtdGvXz8sXrxYrX3p0qXo06ePESIiIiLSH3OetWG0ikRMTIzyZ4lEguXLl2Pnzp1o0qQJAODYsWNIT0/ndSSIiKjcM9EcQC+MlkgkJyerPG7QoAGAR3cBBQAXFxe4uLjw7p9EREQmzGiJxL59+4x1aCIiolfLjEsSJjHYkoiIyJxxsCURERFRGViRICIiMjBTnXGhD0wkiIiIDMyM8wh2bRAREZHuWJEgIiIyNDMuSTCRICIiMjDO2iAiIiIqAysSREREBsZZG0RERKQzM84jmEgQEREZnBlnEhwjQURERDpjRYKIiMjAzHnWBhMJIiIiAzPnwZbs2iAiIiKdMZEgIiIyMImeFm0dPHgQ7777Ljw9PSGRSLB582aV9UIITJ48GR4eHrCxsUFYWBhSU1O1OgYTCSIiIkMzUiZx//591K1bFwsXLixz/axZs7BgwQIsWbIEx44dg62tLdq1a4eCggKNj8ExEkRERGaqQ4cO6NChQ5nrhBCYN28eJk6ciM6dOwMA/ve//8HNzQ2bN29Gr169NDoGKxJEREQGJtHTP4VCgby8PJVFoVDoFFNaWhoyMzMRFhambJPL5WjcuDGSkpI03g8TCSIiIgOTSPSzxMfHQy6Xqyzx8fE6xZSZmQkAcHNzU2l3c3NTrtMEuzaIiIjKidjYWMTExKi0yWQyI0XzCBMJIiIiA9PXZSRkMpneEgd3d3cAQFZWFjw8PJTtWVlZqFevnsb7YdcGERGRoRlr/udz+Pj4wN3dHXv27FG25eXl4dixYwgJCdF4P6xIEBERGZixLpGdn5+PS5cuKR+npaXhzJkzcHJygpeXF0aPHo3p06ejRo0a8PHxwaRJk+Dp6YkuXbpofAwmEkRERGbq5MmTaNWqlfLx4/EVkZGRWLVqFcaPH4/79+9j6NChyMnJQbNmzfDbb7/B2tpa42NIhBBC75EbWUGxsSMgMk2VGg03dghEJudh8tcGP0b6Hd2maD7Ny8m4AyvLwooEERGRgZnxPbs42JKIiIh0x4oEERGRgZnzbcSZSBARERmc+WYS7NogIiIinbEiQUREZGDs2iAiIiKdmXEewa4NIiIi0h0rEkRERAbGrg0iIiLSmbHutfEqMJEgIiIyNPPNIzhGgoiIiHTHigQREZGBmXFBgokEERGRoZnzYEt2bRAREZHOWJEgIiIyMM7aICIiIt2Zbx7Brg0iIiLSHSsSREREBmbGBQkmEkRERIbGWRtEREREZWBFgoiIyMA4a4OIiIh0xq4NIiIiojIwkSAiIiKdsWuDiIjIwMy5a4OJBBERkYGZ82BLdm0QERGRzliRICIiMjB2bRAREZHOzDiPYNcGERER6Y4VCSIiIkMz45IEEwkiIiID46wNIiIiojKwIkFERGRgnLVBREREOjPjPIKJBBERkcGZcSbBMRJERESkM1YkiIiIDMycZ20wkSAiIjIwcx5sya4NIiIi0plECCGMHQSZJ4VCgfj4eMTGxkImkxk7HCKTwc8GmRMmEmQweXl5kMvlyM3NhYODg7HDITIZ/GyQOWHXBhEREemMiQQRERHpjIkEERER6YyJBBmMTCbDlClTOJiM6Cn8bJA54WBLIiIi0hkrEkRERKQzJhJERESkMyYSREREpDMmEqSVAQMGoEuXLsrHb775JkaPHm20eIgM6VW8v5/+TBGVN7xpF72UTZs2wcrKythhlKlatWoYPXo0Ex0yafPnzwfHvFN5xkSCXoqTk5OxQyAq1+RyubFDIHop7NowY2+++SZGjBiB0aNHo1KlSnBzc8OyZctw//59DBw4EPb29vDz88Ovv/4KACgpKcHgwYPh4+MDGxsb+Pv7Y/78+S88xpPf+DMyMtCxY0fY2NjAx8cH69atQ7Vq1TBv3jzlNhKJBMuXL0fXrl1RsWJF1KhRA1u2bFGu1ySOx+XgL7/8Eh4eHnB2dkZUVBSKioqUcf3zzz+Ijo6GRCKBxJzv4UsGVVxcjOHDh0Mul8PFxQWTJk1SVhAUCgXGjh2L1157Dba2tmjcuDH279+vfO6qVavg6OiIHTt2IDAwEHZ2dmjfvj0yMjKU2zzdtXHv3j306dMHtra28PDwQEJCgtrnrFq1apg5cyYGDRoEe3t7eHl5YenSpYZ+KYjKxETCzK1evRouLi44fvw4RowYgWHDhqF79+5o2rQpTp8+jbZt26Jfv3548OABSktLUaVKFWzcuBHnz5/H5MmT8cknn2DDhg0aH69///64ceMG9u/fjx9//BFLly5Fdna22nbTpk1Djx49cPbsWbz99tvo06cP7ty5AwAax7Fv3z5cvnwZ+/btw+rVq7Fq1SqsWrUKwKMulypVqiAuLg4ZGRkqv7iJtLF69WpUqFABx48fx/z58zF37lwsX74cADB8+HAkJSVh/fr1OHv2LLp374727dsjNTVV+fwHDx7gyy+/xJo1a3Dw4EGkp6dj7NixzzxeTEwMDh8+jC1btmDXrl04dOgQTp8+rbbdnDlz0LBhQyQnJ+Ojjz7CsGHDkJKSov8XgOhFBJmtli1bimbNmikfFxcXC1tbW9GvXz9lW0ZGhgAgkpKSytxHVFSUiIiIUD6OjIwUnTt3VjnGqFGjhBBC/P333wKAOHHihHJ9amqqACASEhKUbQDExIkTlY/z8/MFAPHrr78+81zKisPb21sUFxcr27p37y569uypfOzt7a1yXCJttWzZUgQGBorS0lJl24QJE0RgYKD4559/hKWlpbh+/brKc9q0aSNiY2OFEEIkJiYKAOLSpUvK9QsXLhRubm7Kx09+pvLy8oSVlZXYuHGjcn1OTo6oWLGi8nMmxKP3dt++fZWPS0tLReXKlcXixYv1ct5E2uAYCTNXp04d5c+WlpZwdnZGcHCwss3NzQ0AlFWDhQsXYuXKlUhPT8fDhw9RWFiIevXqaXSslJQUVKhQAa+//rqyzc/PD5UqVXpuXLa2tnBwcFCpXGgSR61atWBpaal87OHhgXPnzmkUK5GmmjRpotI1FhISgjlz5uDcuXMoKSlBzZo1VbZXKBRwdnZWPq5YsSKqV6+ufOzh4VFmlQ4Arly5gqKiIrzxxhvKNrlcDn9/f7Vtn/wMSSQSuLu7P3O/RIbERMLMPT2jQiKRqLQ9/gVZWlqK9evXY+zYsZgzZw5CQkJgb2+P2bNn49ixY68krtLSUgDQOI7n7YPI0PLz82FpaYlTp06pJLQAYGdnp/y5rPep0MMsDb7/yVQwkSClw4cPo2nTpvjoo4+UbZcvX9b4+f7+/iguLkZycjIaNGgAALh06RLu3r37SuN4TCqVoqSkROvnET3p6QT26NGjqFGjBurXr4+SkhJkZ2ejefPmejmWr68vrKyscOLECXh5eQEAcnNzcfHiRbRo0UIvxyDSNw62JKUaNWrg5MmT2LFjBy5evIhJkybhxIkTGj8/ICAAYWFhGDp0KI4fP47k5GQMHToUNjY2Ws2aeNk4HqtWrRoOHjyI69ev49atW1o/nwgA0tPTERMTg5SUFHz33Xf46quvMGrUKNSsWRN9+vRB//79sWnTJqSlpeH48eOIj4/H9u3bdTqWvb09IiMjMW7cOOzbtw9//fUXBg8eDAsLC848IpPFRIKUPvjgA4SHh6Nnz55o3Lgxbt++rVIV0MT//vc/uLm5oUWLFujatSvef/992Nvbw9ra+pXGAQBxcXG4evUqqlevDldXV62fTwQ8mon08OFDvPHGG4iKisKoUaMwdOhQAEBiYiL69++PMWPGwN/fH126dFGpJuhi7ty5CAkJwTvvvIOwsDCEhoYiMDBQq88Q0avE24iTQV27dg1Vq1bF7t270aZNG2OHQ1Tu3L9/H6+99hrmzJmDwYMHGzscIjUcI0F6tXfvXuTn5yM4OBgZGRkYP348qlWrxv5dIg0lJyfjwoULeOONN5Cbm4u4uDgAQOfOnY0cGVHZmEiQXhUVFeGTTz7BlStXYG9vj6ZNm2Lt2rUmez8OIlP05ZdfIiUlBVKpFA0aNMChQ4fg4uJi7LCIysSuDSIiItIZB1sSERGRzphIEBERkc6YSBAREZHOmEgQERGRzphIEJmAAQMGoEuXLsrHb775JkaPHv3K49i/fz8kEglycnIMdoynz1UXryJOItIMEwmiZxgwYAAkEgkkEgmkUin8/PwQFxeH4uJigx9706ZN+OyzzzTa9lX/Ua1WrRrmzZv3So5FRKaP15Egeo727dsjMTERCoUCv/zyC6KiomBlZYXY2Fi1bQsLCyGVSvVyXCcnJ73sh4jI0FiRIHoOmUwGd3d3eHt7Y9iwYQgLC8OWLVsA/F+JfsaMGfD09IS/vz8A4N9//0WPHj3g6OgIJycndO7cGVevXlXus6SkBDExMXB0dISzszPGjx+vdlvpp7s2FAoFJkyYgKpVq0Imk8HPzw8rVqzA1atX0apVKwBApUqVIJFIMGDAAACPbg0fHx8PHx8f2NjYoG7duvjhhx9UjvPLL7+gZs2asLGxQatWrVTi1EVJSQkGDx6sPKa/vz/mz59f5rbTpk2Dq6srHBwc8OGHH6KwsFC5TpPYicg0sCJBpAUbGxvcvn1b+XjPnj1wcHDArl27ADy6sme7du0QEhKCQ4cOoUKFCpg+fTrat2+Ps2fPQiqVYs6cOVi1ahVWrlyJwMBAzJkzBz/99BNat279zOP2798fSUlJWLBgAerWrYu0tDTcunULVatWxY8//oiIiAikpKTAwcEBNjY2AID4+Hh8++23WLJkCWrUqIGDBw+ib9++cHV1RcuWLfHvv/8iPDwcUVFRGDp0KE6ePIkxY8a81OtTWlqKKlWqYOPGjXB2dsaRI0cwdOhQeHh4oEePHiqvm7W1Nfbv34+rV69i4MCBcHZ2xowZMzSKnYhMiCCiMkVGRorOnTsLIYQoLS0Vu3btEjKZTIwdO1a53s3NTSgUCuVz1qxZI/z9/UVpaamyTaFQCBsbG7Fjxw4hhBAeHh5i1qxZyvVFRUWiSpUqymMJIUTLli3FqFGjhBBCpKSkCABi165dZca5b98+AUDcvXtX2VZQUCAqVqwojhw5orLt4MGDRe/evYUQQsTGxoqgoCCV9RMmTFDb19O8vb1FQkLCM9c/LSoqSkRERCgfR0ZGCicnJ3H//n1l2+LFi4WdnZ0oKSnRKPayzpmIjIMVCaLn2LZtG+zs7FBUVITS0lK89957mDp1qnJ9cHCwyriIP/74A5cuXYK9vb3KfgoKCnD58mXk5uYiIyMDjRs3Vq6rUKECGjZsqNa98diZM2dgaWmp1TfxS5cu4cGDB3jrrbdU2gsLC1G/fn0AwN9//60SBwCEhIRofIxnWbhwIVauXIn09HQ8fPgQhYWFqFevnso2devWRcWKFVWOm5+fj3///Rf5+fkvjJ2ITAcTCaLnaNWqFRYvXgypVApPT09UqKD6kbG1tVV5nJ+fjwYNGmDt2rVq+3J1ddUphsddFdrIz88HAGzfvh2vvfaayjqZTKZTHJpYv349xo4dizlz5iAkJAT29vaYPXs2jh07pvE+jBU7EemGiQTRc9ja2sLPz0/j7V9//XV8//33qFy5MhwcHMrcxsPDA8eOHVPeWr24uBinTp3C66+/Xub2wcHBKC0txYEDBxAWFqa2/nFFpKSkRNkWFBQEmUyG9PT0Z1YyAgMDlQNHHzt69OiLT/I5Dh8+jKZNm+Kjjz5Stl2+fFltuz/++AMPHz5UJklHjx6FnZ0dqlatCicnpxfGTkSmg7M2iPSoT58+cHFxQefOnXHo0CGkpaVh//79GDlyJK5duwYAGDVqFD7//HNs3rwZFy5cwEcfffTca0BUq1YNkZGRGDRoEDZv3qzc54YNGwAA3t7ekEgk2LZtG27evIn8/HzY29tj7NixiI6OxurVq3H58mWcPn0aX331FVavXg0A+PDDD5Gamopx48YhJSUF69atw6pVqzQ6z+vXr+PMmTMqy927d1GjRg2cPHkSO3bswMWLFzFp0iScOHFC7fmFhYUYPHgwzp8/j19++QVTpkzB8OHDYWFhoVHsRGRCjD1Ig8hUPTnYUpv1GRkZon///sLFxUXIZDLh6+sr3n//fZGbmyuEeDS4ctSoUcLBwUE4OjqKmJgY0b9//2cOthRCiIcPH4ro6Gjh4eEhpFKp8PPzEytXrlSuj4uLE+7u7kIikYjIyEghxKMBovPmzRP+/v7CyspKuLq6inbt2okDBw4on7d161bh5+cnZDKZaN68uVi5cqVGgy0BqC1r1qwRBQUFYsCAAUIulwtHR0cxbNgw8fHHH4u6deuqvW6TJ08Wzs7Ows7OTrz//vuioKBAuc2LYudgSyLTIRHiGSO8iIiIiF6AXRtERESkMyYSREREpDMmEkRERKQzJhJERESkMyYSREREpDMmEkRERKQzJhJERESkMyYSREREpDMmEkRERKQzJhJERESkMyYSREREpDMmEkRERKSz/wddOouk2C5YEQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Summary Table\n",
        "\n",
        "| Feature | Description |\n",
        "|---------|-------------|\n",
        "| Algorithm | CatBoost Classifier |\n",
        "| Dataset | Mixed numeric & categorical (example: Breast Cancer) |\n",
        "| Hyperparameters | iterations=300, learning_rate=0.05, depth=6 |\n",
        "| Evaluation Metrics | Precision, Recall, F1-score, AUC, Confusion Matrix |\n",
        "| Expected Accuracy | ~95‚Äì97% |\n",
        "| Business Benefit | Reduce defaults, improve risk-based lending, explainable predictions |\n"
      ],
      "metadata": {
        "id": "jHlWlvjXEZwf"
      }
    }
  ]
}